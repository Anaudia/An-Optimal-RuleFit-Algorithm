{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d1d48a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import linecache\n",
    "# from collections import Counter\n",
    "# import os\n",
    "# import tracemalloc\n",
    "#\n",
    "# def display_top(snapshot, key_type='lineno', limit=3):\n",
    "#     snapshot = snapshot.filter_traces((\n",
    "#         tracemalloc.Filter(False, \"<frozen importlib._bootstrap>\"),\n",
    "#         tracemalloc.Filter(False, \"<unknown>\"),\n",
    "#     ))\n",
    "#     top_stats = snapshot.statistics(key_type)\n",
    "#\n",
    "#     print(\"Top %s lines\" % limit)\n",
    "#     for index, stat in enumerate(top_stats[:limit], 1):\n",
    "#         frame = stat.traceback[0]\n",
    "#         # replace \"/path/to/module/file.py\" with \"module/file.py\"\n",
    "#         filename = os.sep.join(frame.filename.split(os.sep)[-2:])\n",
    "#         print(\"#%s: %s:%s: %.1f KiB\"\n",
    "#               % (index, filename, frame.lineno, stat.size / 1024))\n",
    "#         line = linecache.getline(frame.filename, frame.lineno).strip()\n",
    "#         if line:\n",
    "#             print('    %s' % line)\n",
    "#\n",
    "#     other = top_stats[limit:]\n",
    "#     if other:\n",
    "#         size = sum(stat.size for stat in other)\n",
    "#         print(\"%s other: %.1f KiB\" % (len(other), size / 1024))\n",
    "#     total = sum(stat.size for stat in top_stats)\n",
    "#     print(\"Total allocated size: %.1f KiB\" % (total / 1024))\n",
    "\n",
    "# tracemalloc.start()\n",
    "# counts = Counter()\n",
    "# experimentation(classification_dataset_names[0])\n",
    "# snapshot = tracemalloc.take_snapshot()\n",
    "# display_top(snapshot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7306a81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:This copy of Interpretable AI software is for academic purposes only and not for commercial use.\n"
     ]
    }
   ],
   "source": [
    "from ex_func import *\n",
    "from experiment_functions import *\n",
    "import pandas as pd\n",
    "from pmlb import fetch_data, classification_dataset_names\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def get_feature_type(x, include_binary=False):\n",
    "    x.dropna(inplace=True)\n",
    "    if not check_if_all_integers(x):\n",
    "        return 'continuous'\n",
    "    else:\n",
    "        if x.nunique() > 10:\n",
    "            return 'continuous'\n",
    "        if include_binary:\n",
    "            if x.nunique() == 2:\n",
    "                return 'binary'\n",
    "        return 'categorical'\n",
    "\n",
    "def get_target_type(x, include_binary=False):\n",
    "    x.dropna(inplace=True)\n",
    "    if x.dtype=='float64':\n",
    "        return 'continuous'\n",
    "    elif x.dtype=='int64':\n",
    "        if include_binary:\n",
    "            if x.nunique() == 2:\n",
    "                return 'binary'\n",
    "        return 'categorical'\n",
    "    else:\n",
    "        raise ValueError(\"Error getting type\")\n",
    "\n",
    "def check_if_all_integers(x):\n",
    "    \"check a pandas.Series is made of all integers.\"\n",
    "    return all(float(i).is_integer() for i in x.unique())\n",
    "def corr_data_for(df):\n",
    "    TARGET_NAME = 'target'\n",
    "    feat_names = [col for col in df.columns if col!=TARGET_NAME]\n",
    "    types = [get_feature_type(df[col], include_binary=True) for col in feat_names]\n",
    "    col = pd.DataFrame(feat_names,types)\n",
    "    num_col = col[col.index == 'continuous']\n",
    "    bin_col = col[col.index == 'binary']\n",
    "    cat_col = col[col.index == 'categorical']\n",
    "    cat_col = cat_col[0].tolist()\n",
    "    dummy_col = pd.get_dummies(data=df, columns=cat_col)\n",
    "    add_col = dummy_col.shape[1] - df.shape[1]\n",
    "\n",
    "    if (add_col < df.shape[0] *0.3) & (dummy_col.shape[1] <  df.shape[0]) & (df.shape[0] < 10000) & (df.shape[1] < 100):\n",
    "        df = dummy_col\n",
    "        df.columns = df.columns.str.replace('.','_',regex=True)\n",
    "        y = df['target']\n",
    "        X = df.loc[:, df.columns != 'target']\n",
    "        del df\n",
    "        rows_data, columns_data = X.shape\n",
    "        print('Dataset Information')\n",
    "        print('Rows:',rows_data,)\n",
    "        print('Columns:',columns_data)\n",
    "        print('Number of classes:',y.nunique())\n",
    "        print('Continous columns:', len(num_col))\n",
    "        print('Binary columns:', len(bin_col))\n",
    "        print('Categorical columns:',len(cat_col))\n",
    "        print('-------------------------------------------------')\n",
    "    else:\n",
    "        del df\n",
    "        return pd.DataFrame, pd.DataFrame\n",
    "    return y, X"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def split_function(y,X,it):\n",
    "    sc = StandardScaler()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = it, stratify=y)\n",
    "    X_col = X_train.columns\n",
    "    X_test.name = \"X_test\"\n",
    "    X_train.name = \"X_train\"\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    X_train = pd.DataFrame(X_train,columns=X_col)\n",
    "    X_test = pd.DataFrame(X_test,columns=X_col)\n",
    "    return X_train, X_test, y_train, y_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    " #classification_dataset_names = classification_dataset_names[30:33]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def experimentation(classification_dataset,iters):\n",
    "    res_rul = {}\n",
    "    names = ['Reg-CART','CART','ORT','OCT','ORT-H','OCT-H','ORT+ORT-H','OCT+OCT-H']\n",
    "    algorithms = ['LN','SVM','NB','KNN']\n",
    "    pipelines = [LN_pipeline,SVM_pipeline,NB_pipeline,KNN_pipeline]\n",
    "\n",
    "    df = fetch_data(classification_dataset)\n",
    "    print('Numer of NANs: ',df.isna().sum().sum())\n",
    "    y, X = corr_data_for(df)\n",
    "\n",
    "    del df\n",
    "    if X.empty:\n",
    "        return {}\n",
    "\n",
    "    print(color.BOLD + '\\n\\n    ----------------------------------------- {} -----------------------------------------'.format(classification_dataset) + color.END)\n",
    "    for it in range(iters):\n",
    "        X_train, X_test, y_train, y_test = split_function(y,X,it)\n",
    "        col_len = len(X_train.columns)\n",
    "        factors = [0.5,1,1.2,1.4,1.6,1.8,2,2.5,3]\n",
    "\n",
    "        models, performance = generate_tree(X_train, y_train, X_test, y_test, n_num=1, feat_size=len(X.columns),  max_iter_hy=2,sub_paths=True,depth_grid=range(3,4), depth_grid_hy=range(1,3), complexity_bi = 0.001, complexity_hy=0.001,  Reg_CART=False, ORT=False, ORT_H=False, Clas_CART=True, OCT=True, OCT_H=False)\n",
    "\n",
    "        for perf,name in zip(performance,names):\n",
    "            if not not perf:\n",
    "                res_rul[(classification_dataset,name,it,1)] = sum(perf) / len(perf)\n",
    "\n",
    "        act_name = []\n",
    "        act_rules = []\n",
    "        for model,name in zip(models,names):\n",
    "            if (all(model)) & (not not model) & (None not in model):\n",
    "                act_name.append(name)\n",
    "                act_rules.append(model)\n",
    "\n",
    "        datasets = gen_train_and_test_features(act_rules ,act_name , X_train, X_test)\n",
    "\n",
    "        for model in datasets.keys():\n",
    "            X_train_rules_and_features, X_test_rules_and_features = datasets[model][0]\n",
    "            X_train_only_rules, X_test_only_rules = datasets[model][1]\n",
    "\n",
    "            for algorithm,pipeline in zip(algorithms,pipelines):\n",
    "                res_rul[(classification_dataset,model + f'_{algorithm}_rules',it,'all')] = pipeline(X_train_only_rules, X_test_only_rules, y_train, y_test)\n",
    "                res_rul[(classification_dataset,model + f'_{algorithm}_rules_and_features',it,'all')] = pipeline(X_train_rules_and_features, X_test_rules_and_features, y_train, y_test)\n",
    "\n",
    "            for fact in factors:\n",
    "                if (round(len(X_train_rules_and_features.columns)*fact) <= X_train.shape[0]) & (round(col_len*fact) <= len(X_train_rules_and_features.columns)):\n",
    "                    min_feat_rule = round(col_len*fact)\n",
    "\n",
    "                    if (round(col_len*fact) > len(X_train_only_rules.columns)) & (fact != 0.5):\n",
    "                        len_rule = 1\n",
    "                        min_rule = len(X_train_only_rules.columns)\n",
    "                    else:\n",
    "                        len_rule = fact\n",
    "                        min_rule = min(round(col_len*fact),len(X_train_only_rules.columns))\n",
    "\n",
    "                    cols = SelectKBest(k=min_feat_rule).fit(X_train_rules_and_features,y_train).get_feature_names_out()\n",
    "                    cols_rule = SelectKBest(k=min_rule).fit(X_train_only_rules,y_train).get_feature_names_out()\n",
    "\n",
    "                else:\n",
    "                     continue\n",
    "\n",
    "                for algorithm,pipeline in zip(algorithms,pipelines):\n",
    "                    res_rul[(classification_dataset,model + f'_{algorithm}_rules',it,len_rule)] = pipeline(X_train_only_rules[cols_rule], X_test_only_rules[cols_rule], y_train, y_test)\n",
    "                    res_rul[(classification_dataset,model + f'_{algorithm}_rules_and_features',it,fact)] = pipeline(X_train_rules_and_features[cols], X_test_rules_and_features[cols], y_train, y_test)\n",
    "\n",
    "        for algorithm,pipeline in zip(algorithms,pipelines):\n",
    "            res_rul[(classification_dataset,algorithm,it,1)] = pipeline(X_train, X_test, y_train, y_test)\n",
    "        del X_train, X_test\n",
    "    return res_rul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# for data in classification_dataset_names:\n",
    "#     data = fetch_data(data)\n",
    "#     print(data.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numer of NANs:  0\n",
      "Numer of NANs:  0\n",
      "Dataset Information\n",
      "Rows: 1600\n",
      "Columns: 60\n",
      "Number of classes: 2\n",
      "Continous columns: 0\n",
      "Binary columns: 0\n",
      "Categorical columns: 20\n",
      "-------------------------------------------------\n",
      "\u001B[1m\n",
      "\n",
      "    ----------------------------------------- GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1 -----------------------------------------\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ Warning: This copy of Interpretable AI software is for academic purposes only and not for commercial use.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification CART mean performance:  0.50625\n",
      "\n",
      "\n",
      "Classification OCT performance:  0.65\n",
      "\n",
      "\n",
      "Numer of NANs:  0\n",
      "Dataset Information\n",
      "Rows: 1600\n",
      "Columns: 56\n",
      "Number of classes: 2\n",
      "Continous columns: 0\n",
      "Binary columns: 2\n",
      "Categorical columns: 18\n",
      "-------------------------------------------------\n",
      "\u001B[1m\n",
      "\n",
      "    ----------------------------------------- GAMETES_Epistasis_2_Way_20atts_0.4H_EDM_1_1 -----------------------------------------\u001B[0m\n",
      "Classification CART mean performance:  0.50625\n",
      "\n",
      "\n",
      "Classification OCT performance:  0.8\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [7], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m orig \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m classification_dataset \u001B[38;5;129;01min\u001B[39;00m classification_dataset_names:\n\u001B[0;32m----> 3\u001B[0m     res_rul \u001B[38;5;241m=\u001B[39m \u001B[43mexperimentation\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclassification_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m     orig\u001B[38;5;241m.\u001B[39mupdate(res_rul)\n",
      "Cell \u001B[0;32mIn [6], line 55\u001B[0m, in \u001B[0;36mexperimentation\u001B[0;34m(classification_dataset, iters)\u001B[0m\n\u001B[1;32m     52\u001B[0m         len_rule \u001B[38;5;241m=\u001B[39m fact\n\u001B[1;32m     53\u001B[0m         min_rule \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmin\u001B[39m(\u001B[38;5;28mround\u001B[39m(col_len\u001B[38;5;241m*\u001B[39mfact),\u001B[38;5;28mlen\u001B[39m(X_train_only_rules\u001B[38;5;241m.\u001B[39mcolumns))\n\u001B[0;32m---> 55\u001B[0m     cols \u001B[38;5;241m=\u001B[39m \u001B[43mSelectKBest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mk\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmin_feat_rule\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train_rules_and_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mget_feature_names_out()\n\u001B[1;32m     56\u001B[0m     cols_rule \u001B[38;5;241m=\u001B[39m SelectKBest(k\u001B[38;5;241m=\u001B[39mmin_rule)\u001B[38;5;241m.\u001B[39mfit(X_train_only_rules,y_train)\u001B[38;5;241m.\u001B[39mget_feature_names_out()\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m/Library/Python/3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:461\u001B[0m, in \u001B[0;36m_BaseFilter.fit\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m    444\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y):\n\u001B[1;32m    445\u001B[0m     \u001B[38;5;124;03m\"\"\"Run score function on (X, y) and get the appropriate features.\u001B[39;00m\n\u001B[1;32m    446\u001B[0m \n\u001B[1;32m    447\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    459\u001B[0m \u001B[38;5;124;03m        Returns the instance itself.\u001B[39;00m\n\u001B[1;32m    460\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 461\u001B[0m     X, y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    462\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsc\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmulti_output\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\n\u001B[1;32m    463\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    465\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m callable(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscore_func):\n\u001B[1;32m    466\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[1;32m    467\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe score function should be a callable, \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m (\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m) was passed.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    468\u001B[0m             \u001B[38;5;241m%\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscore_func, \u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscore_func))\n\u001B[1;32m    469\u001B[0m         )\n",
      "File \u001B[0;32m/Library/Python/3.9/site-packages/sklearn/base.py:596\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[0;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[1;32m    594\u001B[0m         y \u001B[38;5;241m=\u001B[39m check_array(y, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_y_params)\n\u001B[1;32m    595\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 596\u001B[0m         X, y \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_X_y\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcheck_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    597\u001B[0m     out \u001B[38;5;241m=\u001B[39m X, y\n\u001B[1;32m    599\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m check_params\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mensure_2d\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m):\n",
      "File \u001B[0;32m/Library/Python/3.9/site-packages/sklearn/utils/validation.py:1074\u001B[0m, in \u001B[0;36mcheck_X_y\u001B[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001B[0m\n\u001B[1;32m   1069\u001B[0m         estimator_name \u001B[38;5;241m=\u001B[39m _check_estimator_name(estimator)\n\u001B[1;32m   1070\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1071\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m requires y to be passed, but the target y is None\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1072\u001B[0m     )\n\u001B[0;32m-> 1074\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1075\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1076\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maccept_sparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1077\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccept_large_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maccept_large_sparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1078\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1079\u001B[0m \u001B[43m    \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1080\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1081\u001B[0m \u001B[43m    \u001B[49m\u001B[43mforce_all_finite\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_all_finite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1082\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_2d\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_2d\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1083\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_nd\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mallow_nd\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1084\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_min_samples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_min_samples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1085\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_min_features\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_min_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1086\u001B[0m \u001B[43m    \u001B[49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1087\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mX\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1088\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1090\u001B[0m y \u001B[38;5;241m=\u001B[39m _check_y(y, multi_output\u001B[38;5;241m=\u001B[39mmulti_output, y_numeric\u001B[38;5;241m=\u001B[39my_numeric, estimator\u001B[38;5;241m=\u001B[39mestimator)\n\u001B[1;32m   1092\u001B[0m check_consistent_length(X, y)\n",
      "File \u001B[0;32m/Library/Python/3.9/site-packages/sklearn/utils/validation.py:757\u001B[0m, in \u001B[0;36mcheck_array\u001B[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[1;32m    754\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m suppress(\u001B[38;5;167;01mImportError\u001B[39;00m):\n\u001B[1;32m    755\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtypes\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m is_sparse\n\u001B[0;32m--> 757\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(array, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msparse\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[43marray\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdtypes\u001B[49m\u001B[38;5;241m.\u001B[39mapply(is_sparse)\u001B[38;5;241m.\u001B[39many():\n\u001B[1;32m    758\u001B[0m         warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    759\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpandas.DataFrame with sparse columns found.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    760\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIt will be converted to a dense numpy array.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    761\u001B[0m         )\n\u001B[1;32m    763\u001B[0m dtypes_orig \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(array\u001B[38;5;241m.\u001B[39mdtypes)\n",
      "File \u001B[0;32m/Library/Python/3.9/site-packages/pandas/core/generic.py:6073\u001B[0m, in \u001B[0;36mNDFrame.dtypes\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   6045\u001B[0m \u001B[38;5;129m@property\u001B[39m\n\u001B[1;32m   6046\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdtypes\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m   6047\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   6048\u001B[0m \u001B[38;5;124;03m    Return the dtypes in the DataFrame.\u001B[39;00m\n\u001B[1;32m   6049\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   6071\u001B[0m \u001B[38;5;124;03m    dtype: object\u001B[39;00m\n\u001B[1;32m   6072\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 6073\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_mgr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_dtypes\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   6074\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_constructor_sliced(data, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_info_axis, dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mobject_)\n",
      "File \u001B[0;32m/Library/Python/3.9/site-packages/pandas/core/internals/managers.py:267\u001B[0m, in \u001B[0;36mBaseBlockManager.get_dtypes\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    266\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_dtypes\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 267\u001B[0m     dtypes \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marray\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mblk\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mblk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mblocks\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    268\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m dtypes\u001B[38;5;241m.\u001B[39mtake(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mblknos)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "orig = {}\n",
    "for classification_dataset in classification_dataset_names:\n",
    "    res_rul = experimentation(classification_dataset,1)\n",
    "    orig.update(res_rul)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "{('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1', 'Reg-CART', 0, 1): nan,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1', 'CART', 0, 1): 0.50625,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1', 'ORT', 0, 1): nan,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1', 'OCT', 0, 1): 0.65,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1', 'ORT-H', 0, 1): nan,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1', 'OCT-H', 0, 1): nan,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'CART_LN_rules',\n  0,\n  'all'): 0.50625,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'CART_LN_rules_and_features',\n  0,\n  'all'): 0.471875,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'CART_SVM_rules',\n  0,\n  'all'): 0.50625,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'CART_SVM_rules_and_features',\n  0,\n  'all'): 0.55,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'CART_NB_rules',\n  0,\n  'all'): 0.4875,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'CART_NB_rules_and_features',\n  0,\n  'all'): 0.484375,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'CART_KNN_rules',\n  0,\n  'all'): 0.5,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'CART_KNN_rules_and_features',\n  0,\n  'all'): 0.503125,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'CART_LN_rules',\n  0,\n  0.5): 0.50625,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'CART_LN_rules_and_features',\n  0,\n  0.5): 0.478125,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'CART_SVM_rules',\n  0,\n  0.5): 0.50625,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'CART_SVM_rules_and_features',\n  0,\n  0.5): 0.484375,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'CART_NB_rules',\n  0,\n  0.5): 0.4875,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'CART_NB_rules_and_features',\n  0,\n  0.5): 0.484375,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'CART_KNN_rules',\n  0,\n  0.5): 0.5,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'CART_KNN_rules_and_features',\n  0,\n  0.5): 0.484375,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'CART_LN_rules',\n  0,\n  1): 0.50625,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'CART_LN_rules_and_features',\n  0,\n  1): 0.471875,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'CART_SVM_rules',\n  0,\n  1): 0.50625,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'CART_SVM_rules_and_features',\n  0,\n  1): 0.496875,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'CART_NB_rules',\n  0,\n  1): 0.4875,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'CART_NB_rules_and_features',\n  0,\n  1): 0.484375,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1', 'CART_KNN_rules', 0, 1): 0.5,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'CART_KNN_rules_and_features',\n  0,\n  1): 0.46875,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'OCT_LN_rules',\n  0,\n  'all'): 0.65,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'OCT_LN_rules_and_features',\n  0,\n  'all'): 0.61875,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'OCT_SVM_rules',\n  0,\n  'all'): 0.65,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'OCT_SVM_rules_and_features',\n  0,\n  'all'): 0.621875,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'OCT_NB_rules',\n  0,\n  'all'): 0.65,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'OCT_NB_rules_and_features',\n  0,\n  'all'): 0.6375,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'OCT_KNN_rules',\n  0,\n  'all'): 0.64375,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'OCT_KNN_rules_and_features',\n  0,\n  'all'): 0.5125,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1', 'OCT_LN_rules', 0, 0.5): 0.65,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'OCT_LN_rules_and_features',\n  0,\n  0.5): 0.640625,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'OCT_SVM_rules',\n  0,\n  0.5): 0.65,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'OCT_SVM_rules_and_features',\n  0,\n  0.5): 0.634375,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1', 'OCT_NB_rules', 0, 0.5): 0.65,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'OCT_NB_rules_and_features',\n  0,\n  0.5): 0.628125,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'OCT_KNN_rules',\n  0,\n  0.5): 0.64375,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'OCT_KNN_rules_and_features',\n  0,\n  0.5): 0.478125,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1', 'OCT_LN_rules', 0, 1): 0.65,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'OCT_LN_rules_and_features',\n  0,\n  1): 0.61875,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1', 'OCT_SVM_rules', 0, 1): 0.65,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'OCT_SVM_rules_and_features',\n  0,\n  1): 0.59375,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1', 'OCT_NB_rules', 0, 1): 0.65,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'OCT_NB_rules_and_features',\n  0,\n  1): 0.6375,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'OCT_KNN_rules',\n  0,\n  1): 0.64375,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'OCT_KNN_rules_and_features',\n  0,\n  1): 0.496875,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'OCT+OCT-H_LN_rules',\n  0,\n  'all'): 0.65,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'OCT+OCT-H_LN_rules_and_features',\n  0,\n  'all'): 0.61875,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'OCT+OCT-H_SVM_rules',\n  0,\n  'all'): 0.65,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'OCT+OCT-H_SVM_rules_and_features',\n  0,\n  'all'): 0.621875,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'OCT+OCT-H_NB_rules',\n  0,\n  'all'): 0.65,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'OCT+OCT-H_NB_rules_and_features',\n  0,\n  'all'): 0.6375,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'OCT+OCT-H_KNN_rules',\n  0,\n  'all'): 0.64375,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'OCT+OCT-H_KNN_rules_and_features',\n  0,\n  'all'): 0.5125,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'OCT+OCT-H_LN_rules',\n  0,\n  0.5): 0.65,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'OCT+OCT-H_LN_rules_and_features',\n  0,\n  0.5): 0.640625,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'OCT+OCT-H_SVM_rules',\n  0,\n  0.5): 0.65,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'OCT+OCT-H_SVM_rules_and_features',\n  0,\n  0.5): 0.634375,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'OCT+OCT-H_NB_rules',\n  0,\n  0.5): 0.65,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'OCT+OCT-H_NB_rules_and_features',\n  0,\n  0.5): 0.628125,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'OCT+OCT-H_KNN_rules',\n  0,\n  0.5): 0.64375,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'OCT+OCT-H_KNN_rules_and_features',\n  0,\n  0.5): 0.478125,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'OCT+OCT-H_LN_rules',\n  0,\n  1): 0.65,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'OCT+OCT-H_LN_rules_and_features',\n  0,\n  1): 0.61875,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'OCT+OCT-H_SVM_rules',\n  0,\n  1): 0.65,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'OCT+OCT-H_SVM_rules_and_features',\n  0,\n  1): 0.59375,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'OCT+OCT-H_NB_rules',\n  0,\n  1): 0.65,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'OCT+OCT-H_NB_rules_and_features',\n  0,\n  1): 0.6375,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'OCT+OCT-H_KNN_rules',\n  0,\n  1): 0.64375,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1',\n  'OCT+OCT-H_KNN_rules_and_features',\n  0,\n  1): 0.496875,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1', 'LN', 0, 1): 0.484375,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1', 'SVM', 0, 1): 0.55,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1', 'NB', 0, 1): 0.5,\n ('GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1', 'KNN', 0, 1): 0.5}"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from joblib import delayed\n",
    "# from tqdm import tqdm\n",
    "# res_rul = ProgressParallel(n_jobs=4)(delayed(experimentation)(data) for data in classification_dataset_names)\n",
    "\n",
    "# result = {}\n",
    "# for d in res_rul:\n",
    "#     result.update(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import os\n",
    "# files = os.listdir('C:/Users/paulr/PycharmProjects/pythonProject/ORRFA-2/')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# list_of_dfs = []\n",
    "# for file in files:\n",
    "#     if file.endswith('pickle'):\n",
    "#         with open(file, 'rb') as handle:\n",
    "#             b = pickle.load(handle)\n",
    "#             # df = pd.concat({k:json_normalize(v, 'scores', ['best']) for k,v in d.items()})\n",
    "#             # df = df.reset_index(level=1, drop=True).rename_axis('names').reset_index()\n",
    "# #             list_of_dfs.append(b)\n",
    "# big_df = pd.concat(list_of_dfs, ignore_index=True)#ignore_index to reset index of big_df\n",
    "# big_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k = pd.DataFrame(orig,index=[0])\n",
    "k = k.stack(level=2).sort_index()\n",
    "k = k.stack(level=2).sort_index()\n",
    "k = k.swaplevel(axis=1)\n",
    "k = k.droplevel(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "k"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# k.to_csv('result_girdsearch.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "k.swaplevel(axis=0).mean(level=0).mean(level=0,axis=1).iloc[1].sort_values(ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t=k.mean(level=0,axis=1)\n",
    "t = t.mean(axis=0)\n",
    "t.sort_values(ascending = False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = k.swaplevel(axis=1)\n",
    "y = y.var(level=0,axis=1)\n",
    "y = y.mean(axis=0)\n",
    "good_tests = y[y < 0.01].index\n",
    "good = list(good_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vaild_results = k.iloc[:,k.columns.isin(good, level=1)]\n",
    "vaild_results=vaild_results.mean(level=0,axis=1)\n",
    "vaild_results.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a935b482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(nrows = 5, ncols = 4, gridspec_kw = {\"hspace\": 0.25})\n",
    "import seaborn as sns\n",
    "fig.set_size_inches(30, 25)\n",
    "iteration = 0\n",
    "\n",
    "for m in range(5):\n",
    "    for j in range(4):\n",
    "\n",
    "        dataset = classification_dataset_names[:20][iteration]\n",
    "\n",
    "        columns = [i for i in k.columns if dataset in i]\n",
    "        sns.boxplot(k[columns], ax = ax[m, j])\n",
    "\n",
    "        ax[m, j].set_title(dataset)\n",
    "\n",
    "        ax[m, j].set_xticklabels(['CART Rules', \"OCT Rules\", \"Logistic Regression\", \"RuleFit\", \"ORRFA\"])\n",
    "\n",
    "        iteration += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94a02e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "fig, ax = plt.subplots()\n",
    "sns.boxplot(data = performance_by_iter)\n",
    "fig.set_size_inches(20, 10)\n",
    "ax.set_xticklabels(performance_by_iter.columns.values)\n",
    "# ax.set_ylim(0.93, 0.995)\n",
    "ax.tick_params(rotation = 0, labelsize = 14)\n",
    "ax.set_ylabel(\"Accuracy\", fontsize = 14)\n",
    "ax.set_title(\"Accuracy of Logistic Regression, RuleFit and ORRFA\", fontsize = 15)\n",
    "# ax.set_ylabel()\n",
    "plt.savefig('Benchmark ORRFA.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "iters=5\n",
    "res_rul = {}\n",
    "sc = StandardScaler()\n",
    "names = ['Reg-CART','CART','ORT','OCT','ORT-H','OCT-H','ORT+ORT-H','OCT+OCT-H']\n",
    "\n",
    "for classification_dataset in classification_dataset_names:\n",
    "    df = fetch_data(classification_dataset)\n",
    "    df, num_col, bin_col, cat_col = corr_data_for(df)\n",
    "    if (df.shape[0] > 10000) | (df.shape[1] > 100) | (df.empty):\n",
    "        continue\n",
    "    y = df['target']\n",
    "    X = df.loc[:, df.columns != 'target']\n",
    "\n",
    "    print(color.BOLD + '\\n\\n    ----------------------------------------- {} -----------------------------------------'.format(classification_dataset) + color.END)\n",
    "    rows_data, columns_data = X.shape\n",
    "    print('Dataset Information')\n",
    "    print('Rows:',rows_data,)\n",
    "    print('Columns:',columns_data)\n",
    "    print('Number of classes:',y.nunique())\n",
    "    print('Continous columns:', len(num_col))\n",
    "    print('Binary columns:', len(bin_col))\n",
    "    print('Categorical columns:',len(cat_col))\n",
    "    print('-------------------------------------------------')\n",
    "\n",
    "    for it in range(iters):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = it, stratify=y)\n",
    "        X_col = X_train.columns\n",
    "        col_len = len(X_col)\n",
    "        X_test.name = \"X_test\"\n",
    "        X_train.name = \"X_train\"\n",
    "        X_train = sc.fit_transform(X_train)\n",
    "        X_test = sc.transform(X_test)\n",
    "        X_train = pd.DataFrame(X_train,columns=X_col)\n",
    "        X_test = pd.DataFrame(X_test,columns=X_col)\n",
    "        factors = ['all',0.5,1,1.2,1.4,1.6,1.8,2,2.5,3]\n",
    "\n",
    "        models, performance = generate_tree(X_train, y_train, X_test, y_test, n_num=1, feat_size=len(X.columns),  max_iter_hy=2,sub_paths=True,depth_grid=range(1,7), depth_grid_hy=range(1,3), complexity_bi = 0.001, complexity_hy=0.001,  Reg_CART=False, ORT=False, ORT_H=False, Clas_CART=True, OCT=True, OCT_H=False)\n",
    "        for perf,name in zip(performance,names):\n",
    "            if not not perf:\n",
    "                res_rul[(classification_dataset,name,it,1)] = sum(perf) / len(perf)\n",
    "\n",
    "        act_name = []\n",
    "        act_rules = []\n",
    "        for model,name in zip(models,names):\n",
    "            if (all(model)) & (not not model) & (None not in model):\n",
    "                act_name.append(name)\n",
    "                act_rules.append(model)\n",
    "\n",
    "        datasets = gen_train_and_test_features(act_rules ,act_name , X_train, X_test)\n",
    "        for model in datasets.keys():\n",
    "            X_train_rules_and_features, X_test_rules_and_features = datasets[model][0]\n",
    "            X_train_only_rules, X_test_only_rules = datasets[model][1]\n",
    "\n",
    "            for len_c in factors:\n",
    "\n",
    "                if len_c == 'all':\n",
    "                    len_rule = 'all'\n",
    "                    cols = SelectKBest(k='all').fit(X_train_rules_and_features,y_train).get_feature_names_out()\n",
    "                    X_train_rules_features = X_train_rules_and_features[cols]\n",
    "                    X_test_rules_features = X_test_rules_and_features[cols]\n",
    "\n",
    "                    cols_1 = SelectKBest(k='all').fit(X_train_only_rules,y_train).get_feature_names_out()\n",
    "                    X_train_rules = X_train_only_rules[cols_1]\n",
    "                    X_test_rules = X_test_only_rules[cols_1]\n",
    "\n",
    "                elif (round(col_len*len_c) <= X_train.shape[0]) & (round(col_len*len_c) <= len(X_train_rules_and_features.columns)):\n",
    "                    min_feat_rule = round(col_len*len_c)\n",
    "                    if (round(col_len*len_c) > len(X_train_only_rules.columns)) & (col_len != 0.5):\n",
    "                        len_rule = 1\n",
    "                        min_rule = len(X_train_only_rules.columns)\n",
    "                    else:\n",
    "                        len_rule = len_c\n",
    "                        min_rule = min(round(col_len*len_c),len(X_train_only_rules.columns))\n",
    "\n",
    "\n",
    "                    cols = SelectKBest(k=min_feat_rule).fit(X_train_rules_and_features,y_train).get_feature_names_out()\n",
    "                    X_train_rules_features = X_train_rules_and_features[cols]\n",
    "                    X_test_rules_features = X_test_rules_and_features[cols]\n",
    "\n",
    "                    cols_1 = SelectKBest(k=min_rule).fit(X_train_only_rules,y_train).get_feature_names_out()\n",
    "                    X_train_rules = X_train_only_rules[cols_1]\n",
    "                    X_test_rules = X_test_only_rules[cols_1]\n",
    "\n",
    "                else:\n",
    "                     continue\n",
    "\n",
    "                # Pipeline models\n",
    "                only_rules_acc_LN = log_regression_pipeline(X_train_rules, X_test_rules, y_train, y_test)\n",
    "                rules_and_features_acc_LN = log_regression_pipeline(X_train_rules_features, X_test_rules_features, y_train, y_test)\n",
    "                res_rul[(classification_dataset,model + \"_LG_rules\",it,len_rule)] = only_rules_acc_LN\n",
    "                res_rul[(classification_dataset,model + \"_LG_rules_and_features\",it,len_c)] = rules_and_features_acc_LN\n",
    "\n",
    "                only_rules_acc_SVM = SVM_pipeline(X_train_rules, X_test_rules, y_train, y_test)\n",
    "                rules_and_features_acc_SVM = SVM_pipeline(X_train_rules_features, X_test_rules_features, y_train, y_test)\n",
    "                res_rul[(classification_dataset,model + \"_SVM_rules\",it,len_rule)] = only_rules_acc_SVM\n",
    "                res_rul[(classification_dataset,model + \"_SVM_rules_and_features\",it,len_c)] = rules_and_features_acc_SVM\n",
    "\n",
    "                only_rules_acc_NB = NB_pipeline(X_train_rules, X_test_rules, y_train, y_test)\n",
    "                rules_and_features_acc_NB = NB_pipeline(X_train_rules_features, X_test_rules_features, y_train, y_test)\n",
    "                res_rul[(classification_dataset,model + \"_NB_rules\",it,len_rule)] = only_rules_acc_NB\n",
    "                res_rul[(classification_dataset,model + \"_NB_rules_and_features\",it,len_c)] = rules_and_features_acc_NB\n",
    "\n",
    "                only_rules_acc_KNN = KNN_pipeline(X_train_rules, X_test_rules, y_train, y_test)\n",
    "                rules_and_features_acc_KNN = KNN_pipeline(X_train_rules_features, X_test_rules_features, y_train, y_test)\n",
    "                res_rul[(classification_dataset,model + \"_KNN_rules\",it,len_rule)] = only_rules_acc_KNN\n",
    "                res_rul[(classification_dataset,model + \"_KNN_rules_and_features\",it,len_c)] = rules_and_features_acc_KNN\n",
    "\n",
    "\n",
    "        res_rul[(classification_dataset,'Logistic_Regression',it,1)] = log_regression_pipeline(X_train, X_test, y_train, y_test)\n",
    "        res_rul[(classification_dataset,\"Support Vector Machine\",it,1)] = SVM_pipeline(X_train, X_test, y_train, y_test)\n",
    "        res_rul[(classification_dataset,\"Naive Bayes\",it,1)] = NB_pipeline(X_train, X_test, y_train, y_test)\n",
    "        res_rul[(classification_dataset,\"K-Nearest-Neighbor\",it,1)] = KNN_pipeline(X_train, X_test, y_train, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "res_rul"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
