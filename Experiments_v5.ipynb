{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d1d48a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import linecache\n",
    "# from collections import Counter\n",
    "# import os\n",
    "# import tracemalloc\n",
    "#\n",
    "# def display_top(snapshot, key_type='lineno', limit=3):\n",
    "#     snapshot = snapshot.filter_traces((\n",
    "#         tracemalloc.Filter(False, \"<frozen importlib._bootstrap>\"),\n",
    "#         tracemalloc.Filter(False, \"<unknown>\"),\n",
    "#     ))\n",
    "#     top_stats = snapshot.statistics(key_type)\n",
    "#\n",
    "#     print(\"Top %s lines\" % limit)\n",
    "#     for index, stat in enumerate(top_stats[:limit], 1):\n",
    "#         frame = stat.traceback[0]\n",
    "#         # replace \"/path/to/module/file.py\" with \"module/file.py\"\n",
    "#         filename = os.sep.join(frame.filename.split(os.sep)[-2:])\n",
    "#         print(\"#%s: %s:%s: %.1f KiB\"\n",
    "#               % (index, filename, frame.lineno, stat.size / 1024))\n",
    "#         line = linecache.getline(frame.filename, frame.lineno).strip()\n",
    "#         if line:\n",
    "#             print('    %s' % line)\n",
    "#\n",
    "#     other = top_stats[limit:]\n",
    "#     if other:\n",
    "#         size = sum(stat.size for stat in other)\n",
    "#         print(\"%s other: %.1f KiB\" % (len(other), size / 1024))\n",
    "#     total = sum(stat.size for stat in top_stats)\n",
    "#     print(\"Total allocated size: %.1f KiB\" % (total / 1024))\n",
    "\n",
    "# tracemalloc.start()\n",
    "# counts = Counter()\n",
    "# experimentation(classification_dataset_names[0])\n",
    "# snapshot = tracemalloc.take_snapshot()\n",
    "# display_top(snapshot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7306a81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:This copy of Interpretable AI software is for academic purposes only and not for commercial use.\n",
      "WARNING:root:Interpretable AI license expires soon: 2022-12-31T00:00:00. If you need to renew, please send us the following machine ID:\n",
      "9ed379f63a363f5e759aa0e824692d130d8d8ad83880517bac52e890496b43cf\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from ex_func import *\n",
    "from experiment_functions import *\n",
    "import pandas as pd\n",
    "from pmlb import fetch_data, classification_dataset_names, regression_dataset_names\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def get_feature_type(x, include_binary=False):\n",
    "    x.dropna(inplace=True)\n",
    "    if not check_if_all_integers(x):\n",
    "        return 'continuous'\n",
    "    else:\n",
    "        if x.nunique() > 10:\n",
    "            return 'continuous'\n",
    "        if include_binary:\n",
    "            if x.nunique() == 2:\n",
    "                return 'binary'\n",
    "        return 'categorical'\n",
    "\n",
    "def get_target_type(x, include_binary=False):\n",
    "    x.dropna(inplace=True)\n",
    "    if x.dtype=='float64':\n",
    "        return 'continuous'\n",
    "    elif x.dtype=='int64':\n",
    "        if include_binary:\n",
    "            if x.nunique() == 2:\n",
    "                return 'binary'\n",
    "        return 'categorical'\n",
    "    else:\n",
    "        raise ValueError(\"Error getting type\")\n",
    "\n",
    "def check_if_all_integers(x):\n",
    "    \"check a pandas.Series is made of all integers.\"\n",
    "    return all(float(i).is_integer() for i in x.unique())\n",
    "def corr_data_for(df):\n",
    "    TARGET_NAME = 'target'\n",
    "    feat_names = [col for col in df.columns if col!=TARGET_NAME]\n",
    "    types = [get_feature_type(df[col], include_binary=True) for col in feat_names]\n",
    "    col = pd.DataFrame(feat_names,types)\n",
    "    num_col = col[col.index == 'continuous']\n",
    "    bin_col = col[col.index == 'binary']\n",
    "    cat_col = col[col.index == 'categorical']\n",
    "    cat_col = cat_col[0].tolist()\n",
    "    dummy_col = pd.get_dummies(data=df, columns=cat_col)\n",
    "    add_col = dummy_col.shape[1] - df.shape[1]\n",
    "\n",
    "    if (add_col < df.shape[0] *0.3) & (dummy_col.shape[1] <  df.shape[0]) & (df.shape[0] < 10000) & (df.shape[1] < 100):\n",
    "        df = dummy_col\n",
    "        df.columns = df.columns.str.replace('.','_',regex=True)\n",
    "        y = df['target']\n",
    "        X = df.loc[:, df.columns != 'target']\n",
    "        del df\n",
    "        rows_data, columns_data = X.shape\n",
    "        print('Dataset Information')\n",
    "        print('Rows:',rows_data,)\n",
    "        print('Columns:',columns_data)\n",
    "        print('Number of classes:',y.nunique())\n",
    "        print('Continous columns:', len(num_col))\n",
    "        print('Binary columns:', len(bin_col))\n",
    "        print('Categorical columns:',len(cat_col))\n",
    "        print('-------------------------------------------------')\n",
    "    else:\n",
    "        del df\n",
    "        return pd.DataFrame, pd.DataFrame\n",
    "    return y, X"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def split_function(y,X,it):\n",
    "    sc = StandardScaler()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = it\n",
    "                                                        #,stratify=y\n",
    "                                                        )\n",
    "    X_col = X_train.columns\n",
    "    X_test.name = \"X_test\"\n",
    "    X_train.name = \"X_train\"\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    X_train = pd.DataFrame(X_train,columns=X_col)\n",
    "    X_test = pd.DataFrame(X_test,columns=X_col)\n",
    "    return X_train, X_test, y_train, y_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# regression_dataset_names = list(np.setdiff1d(regression_dataset_names, ['527_analcatdata_election2000', '542_pollution', '659_sleuth_ex1714',        '678_visualizing_environmental', '192_vineyard', '522_pm10',        '665_sleuth_case2002', 'titanic']))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def experimentation(classification_dataset):\n",
    "    res_rul = {}\n",
    "    rules_alg = []\n",
    "    coefficients = []\n",
    "    names = ['Reg-CART','CART','ORT','OCT','ORT-H','OCT-H','ORT+ORT-H','OCT+OCT-H']\n",
    "    algorithms = ['LR','LS','RG']\n",
    "    pipelines = [LR_pipeline]\n",
    "\n",
    "    iters = 1\n",
    "    df = fetch_data(classification_dataset)\n",
    "    df.drop(['Density','Abdomen'],inplace=True,axis=1)\n",
    "    print('Numer of NANs: ',df.isna().sum().sum())\n",
    "    y, X = corr_data_for(df)\n",
    "\n",
    "    del df\n",
    "    if X.empty:\n",
    "        return {}\n",
    "    if len(set(y)) < 50 | ('fri' in classification_dataset):\n",
    "        return {}\n",
    "\n",
    "\n",
    "    print(color.BOLD + '\\n\\n    ----------------------------------------- {} -----------------------------------------'.format(classification_dataset) + color.END)\n",
    "    for it in range(iters):\n",
    "        X_train, X_test, y_train, y_test = split_function(y,X,it)\n",
    "        col_len = len(X_train.columns)\n",
    "        factors = [0.5,1,1.2,1.4,1.6,1.8,2,2.5,3]\n",
    "\n",
    "        models, performance = generate_tree(X_train, y_train, X_test, y_test, n_num=1, feat_size=len(X.columns),  max_iter_hy=2,sub_paths=True,depth_grid=range(3,4), depth_grid_hy=range(1,2), complexity_bi = 0.0001, complexity_hy=0.0001,  Reg_CART=True, ORT=True, ORT_H=False, Clas_CART=False, OCT=False, OCT_H=False)\n",
    "\n",
    "        for perf,name in zip(performance,names):\n",
    "            if not not perf:\n",
    "                res_tree = sum(perf) / len(perf)\n",
    "                res_rul[(classification_dataset,name,it,1)] = res_tree\n",
    "                res_rul[(classification_dataset,name,it,'all')] = res_tree\n",
    "\n",
    "        act_name = []\n",
    "        act_rules = []\n",
    "        for model,name in zip(models,names):\n",
    "            if (all(model)) & (not not model) & (None not in model):\n",
    "                act_name.append(name)\n",
    "                act_rules.append(model)\n",
    "        datasets = gen_train_and_test_features(act_rules ,act_name , X_train, X_test)\n",
    "\n",
    "        for model in datasets.keys():\n",
    "            X_train_rules_and_features, X_test_rules_and_features = datasets[model][0]\n",
    "            rules_alg.append(X_train_rules_and_features.columns)\n",
    "            X_train_only_rules, X_test_only_rules = datasets[model][1]\n",
    "\n",
    "            for algorithm,pipeline in zip(algorithms,pipelines):\n",
    "                pip_result_only_rules, coef = pipeline(X_train_only_rules, X_test_only_rules, y_train, y_test)\n",
    "                pip_result_rules_features, coef  = pipeline(X_train_rules_and_features, X_test_rules_and_features, y_train, y_test)\n",
    "                coefficients.append(coef)\n",
    "                res_rul[(classification_dataset,model + f'_{algorithm}_rules',it,'all')] = pip_result_only_rules\n",
    "                res_rul[(classification_dataset,model + f'_{algorithm}_rules_and_features',it,'all')] = pip_result_rules_features\n",
    "\n",
    "            for fact in factors:\n",
    "                if (round(len(X_train_rules_and_features.columns)*fact) <= X_train.shape[0]) & (round(col_len*fact) <= len(X_train_rules_and_features.columns)):\n",
    "                    min_feat_rule = round(col_len*fact)\n",
    "\n",
    "                    if (round(col_len*fact) > len(X_train_only_rules.columns)) & (fact != 0.5):\n",
    "                        len_rule = 1\n",
    "                        min_rule = len(X_train_only_rules.columns)\n",
    "                    else:\n",
    "                        len_rule = fact\n",
    "                        min_rule = min(round(col_len*fact),len(X_train_only_rules.columns))\n",
    "\n",
    "                    cols = SelectKBest(k=min_feat_rule).fit(X_train_rules_and_features,y_train).get_feature_names_out()\n",
    "                    cols_rule = SelectKBest(k=min_rule).fit(X_train_only_rules,y_train).get_feature_names_out()\n",
    "\n",
    "                else:\n",
    "                     continue\n",
    "\n",
    "                for algorithm,pipeline in zip(algorithms,pipelines):\n",
    "                    pip_result_only_rules, coef = pipeline(X_train_only_rules[cols_rule], X_test_only_rules[cols_rule], y_train, y_test)\n",
    "                    pip_result_rules_features, coef = pipeline(X_train_rules_and_features[cols], X_test_rules_and_features[cols], y_train, y_test)\n",
    "                    res_rul[(classification_dataset,model + f'_{algorithm}_rules',it,len_rule)] = pip_result_only_rules\n",
    "                    res_rul[(classification_dataset,model + f'_{algorithm}_rules_and_features',it,fact)] = pip_result_rules_features\n",
    "\n",
    "        for algorithm,pipeline in zip(algorithms,pipelines):\n",
    "            pip_result = pipeline(X_train, X_test, y_train, y_test)\n",
    "            res_rul[(classification_dataset,algorithm,it,1)] = pip_result\n",
    "            res_rul[(classification_dataset,algorithm,it,'all')] = pip_result\n",
    "        del X_train, X_test\n",
    "\n",
    "    return res_rul, rules_alg, coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "['1027_ESL',\n '1028_SWD',\n '1029_LEV',\n '1030_ERA',\n '1089_USCrime',\n '1096_FacultySalaries',\n '1191_BNG_pbc',\n '1193_BNG_lowbwt',\n '1196_BNG_pharynx',\n '1199_BNG_echoMonths',\n '1201_BNG_breastTumor',\n '1203_BNG_pwLinear',\n '1595_poker',\n '192_vineyard',\n '195_auto_price',\n '197_cpu_act',\n '201_pol',\n '207_autoPrice',\n '210_cloud',\n '215_2dplanes',\n '218_house_8L',\n '225_puma8NH',\n '227_cpu_small',\n '228_elusage',\n '229_pwLinear',\n '230_machine_cpu',\n '294_satellite_image',\n '344_mv',\n '4544_GeographicalOriginalofMusic',\n '485_analcatdata_vehicle',\n '503_wind',\n '505_tecator',\n '519_vinnie',\n '522_pm10',\n '523_analcatdata_neavote',\n '527_analcatdata_election2000',\n '529_pollen',\n '537_houses',\n '542_pollution',\n '547_no2',\n '556_analcatdata_apnea2',\n '557_analcatdata_apnea1',\n '560_bodyfat',\n '561_cpu',\n '562_cpu_small',\n '564_fried',\n '573_cpu_act',\n '574_house_16H',\n '579_fri_c0_250_5',\n '581_fri_c3_500_25',\n '582_fri_c1_500_25',\n '583_fri_c1_1000_50',\n '584_fri_c4_500_25',\n '586_fri_c3_1000_25',\n '588_fri_c4_1000_100',\n '589_fri_c2_1000_25',\n '590_fri_c0_1000_50',\n '591_fri_c1_100_10',\n '592_fri_c4_1000_25',\n '593_fri_c1_1000_10',\n '594_fri_c2_100_5',\n '595_fri_c0_1000_10',\n '596_fri_c2_250_5',\n '597_fri_c2_500_5',\n '598_fri_c0_1000_25',\n '599_fri_c2_1000_5',\n '601_fri_c1_250_5',\n '602_fri_c3_250_10',\n '603_fri_c0_250_50',\n '604_fri_c4_500_10',\n '605_fri_c2_250_25',\n '606_fri_c2_1000_10',\n '607_fri_c4_1000_50',\n '608_fri_c3_1000_10',\n '609_fri_c0_1000_5',\n '611_fri_c3_100_5',\n '612_fri_c1_1000_5',\n '613_fri_c3_250_5',\n '615_fri_c4_250_10',\n '616_fri_c4_500_50',\n '617_fri_c3_500_5',\n '618_fri_c3_1000_50',\n '620_fri_c1_1000_25',\n '621_fri_c0_100_10',\n '622_fri_c2_1000_50',\n '623_fri_c4_1000_10',\n '624_fri_c0_100_5',\n '626_fri_c2_500_50',\n '627_fri_c2_500_10',\n '628_fri_c3_1000_5',\n '631_fri_c1_500_5',\n '633_fri_c0_500_25',\n '634_fri_c2_100_10',\n '635_fri_c0_250_10',\n '637_fri_c1_500_50',\n '641_fri_c1_500_10',\n '643_fri_c2_500_25',\n '644_fri_c4_250_25',\n '645_fri_c3_500_50',\n '646_fri_c3_500_10',\n '647_fri_c1_250_10',\n '648_fri_c1_250_50',\n '649_fri_c0_500_5',\n '650_fri_c0_500_50',\n '651_fri_c0_100_25',\n '653_fri_c0_250_25',\n '654_fri_c0_500_10',\n '656_fri_c1_100_5',\n '657_fri_c2_250_10',\n '658_fri_c3_250_25',\n '659_sleuth_ex1714',\n '663_rabe_266',\n '665_sleuth_case2002',\n '666_rmftsa_ladata',\n '678_visualizing_environmental',\n '687_sleuth_ex1605',\n '690_visualizing_galaxy',\n '695_chatfield_4',\n '706_sleuth_case1202',\n '712_chscase_geyser1',\n 'banana',\n 'titanic']"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_dataset_names"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "classification_dataset_names = ['560_bodyfat']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "['560_bodyfat']"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_dataset_names"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "data = fetch_data('560_bodyfat')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "data": {
      "text/plain": "     Density   Age  Weight  Height       Neck       Chest     Abdomen  \\\n0     1.0708  23.0  154.25   67.75  36.200001   93.099998   85.199997   \n1     1.0853  22.0  173.25   72.25  38.500000   93.599998   83.000000   \n2     1.0414  22.0  154.00   66.25  34.000000   95.800003   87.900002   \n3     1.0751  26.0  184.75   72.25  37.400002  101.800003   86.400002   \n4     1.0340  24.0  184.25   71.25  34.400002   97.300003  100.000000   \n..       ...   ...     ...     ...        ...         ...         ...   \n247   1.0736  70.0  134.25   67.00  34.900002   89.199997   83.599998   \n248   1.0236  72.0  201.00   69.75  40.900002  108.500000  105.000000   \n249   1.0328  72.0  186.75   66.00  38.900002  111.099998  111.500000   \n250   1.0399  72.0  190.75   70.50  38.900002  108.300003  101.300003   \n251   1.0271  74.0  207.50   70.00  40.799999  112.400002  108.500000   \n\n            Hip      Thigh       Knee      Ankle     Biceps    Forearm  \\\n0     94.500000  59.000000  37.299999  21.900000  32.000000  27.400000   \n1     98.699997  58.700001  37.299999  23.400000  30.500000  28.900000   \n2     99.199997  59.599998  38.900002  24.000000  28.799999  25.200001   \n3    101.199997  60.099998  37.299999  22.799999  32.400002  29.400000   \n4    101.900002  63.200001  42.200001  24.000000  32.200001  27.700001   \n..          ...        ...        ...        ...        ...        ...   \n247   88.800003  49.599998  34.799999  21.500000  25.600000  25.700001   \n248  104.500000  59.599998  40.799999  23.200001  35.200001  28.600000   \n249  101.699997  60.299999  37.299999  21.500000  31.299999  27.200001   \n250   97.800003  56.000000  41.599998  22.700001  30.500000  29.400000   \n251  107.099998  59.299999  42.200001  24.600000  33.700001  30.000000   \n\n         Wrist     target  \n0    17.100000  12.300000  \n1    18.200001   6.100000  \n2    16.600000  25.299999  \n3    18.200001  10.400000  \n4    17.700001  28.700001  \n..         ...        ...  \n247  18.500000  11.000000  \n248  20.100000  33.599998  \n249  18.000000  29.299999  \n250  19.799999  26.000000  \n251  20.900000  31.900000  \n\n[252 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Density</th>\n      <th>Age</th>\n      <th>Weight</th>\n      <th>Height</th>\n      <th>Neck</th>\n      <th>Chest</th>\n      <th>Abdomen</th>\n      <th>Hip</th>\n      <th>Thigh</th>\n      <th>Knee</th>\n      <th>Ankle</th>\n      <th>Biceps</th>\n      <th>Forearm</th>\n      <th>Wrist</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0708</td>\n      <td>23.0</td>\n      <td>154.25</td>\n      <td>67.75</td>\n      <td>36.200001</td>\n      <td>93.099998</td>\n      <td>85.199997</td>\n      <td>94.500000</td>\n      <td>59.000000</td>\n      <td>37.299999</td>\n      <td>21.900000</td>\n      <td>32.000000</td>\n      <td>27.400000</td>\n      <td>17.100000</td>\n      <td>12.300000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0853</td>\n      <td>22.0</td>\n      <td>173.25</td>\n      <td>72.25</td>\n      <td>38.500000</td>\n      <td>93.599998</td>\n      <td>83.000000</td>\n      <td>98.699997</td>\n      <td>58.700001</td>\n      <td>37.299999</td>\n      <td>23.400000</td>\n      <td>30.500000</td>\n      <td>28.900000</td>\n      <td>18.200001</td>\n      <td>6.100000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0414</td>\n      <td>22.0</td>\n      <td>154.00</td>\n      <td>66.25</td>\n      <td>34.000000</td>\n      <td>95.800003</td>\n      <td>87.900002</td>\n      <td>99.199997</td>\n      <td>59.599998</td>\n      <td>38.900002</td>\n      <td>24.000000</td>\n      <td>28.799999</td>\n      <td>25.200001</td>\n      <td>16.600000</td>\n      <td>25.299999</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0751</td>\n      <td>26.0</td>\n      <td>184.75</td>\n      <td>72.25</td>\n      <td>37.400002</td>\n      <td>101.800003</td>\n      <td>86.400002</td>\n      <td>101.199997</td>\n      <td>60.099998</td>\n      <td>37.299999</td>\n      <td>22.799999</td>\n      <td>32.400002</td>\n      <td>29.400000</td>\n      <td>18.200001</td>\n      <td>10.400000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0340</td>\n      <td>24.0</td>\n      <td>184.25</td>\n      <td>71.25</td>\n      <td>34.400002</td>\n      <td>97.300003</td>\n      <td>100.000000</td>\n      <td>101.900002</td>\n      <td>63.200001</td>\n      <td>42.200001</td>\n      <td>24.000000</td>\n      <td>32.200001</td>\n      <td>27.700001</td>\n      <td>17.700001</td>\n      <td>28.700001</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>247</th>\n      <td>1.0736</td>\n      <td>70.0</td>\n      <td>134.25</td>\n      <td>67.00</td>\n      <td>34.900002</td>\n      <td>89.199997</td>\n      <td>83.599998</td>\n      <td>88.800003</td>\n      <td>49.599998</td>\n      <td>34.799999</td>\n      <td>21.500000</td>\n      <td>25.600000</td>\n      <td>25.700001</td>\n      <td>18.500000</td>\n      <td>11.000000</td>\n    </tr>\n    <tr>\n      <th>248</th>\n      <td>1.0236</td>\n      <td>72.0</td>\n      <td>201.00</td>\n      <td>69.75</td>\n      <td>40.900002</td>\n      <td>108.500000</td>\n      <td>105.000000</td>\n      <td>104.500000</td>\n      <td>59.599998</td>\n      <td>40.799999</td>\n      <td>23.200001</td>\n      <td>35.200001</td>\n      <td>28.600000</td>\n      <td>20.100000</td>\n      <td>33.599998</td>\n    </tr>\n    <tr>\n      <th>249</th>\n      <td>1.0328</td>\n      <td>72.0</td>\n      <td>186.75</td>\n      <td>66.00</td>\n      <td>38.900002</td>\n      <td>111.099998</td>\n      <td>111.500000</td>\n      <td>101.699997</td>\n      <td>60.299999</td>\n      <td>37.299999</td>\n      <td>21.500000</td>\n      <td>31.299999</td>\n      <td>27.200001</td>\n      <td>18.000000</td>\n      <td>29.299999</td>\n    </tr>\n    <tr>\n      <th>250</th>\n      <td>1.0399</td>\n      <td>72.0</td>\n      <td>190.75</td>\n      <td>70.50</td>\n      <td>38.900002</td>\n      <td>108.300003</td>\n      <td>101.300003</td>\n      <td>97.800003</td>\n      <td>56.000000</td>\n      <td>41.599998</td>\n      <td>22.700001</td>\n      <td>30.500000</td>\n      <td>29.400000</td>\n      <td>19.799999</td>\n      <td>26.000000</td>\n    </tr>\n    <tr>\n      <th>251</th>\n      <td>1.0271</td>\n      <td>74.0</td>\n      <td>207.50</td>\n      <td>70.00</td>\n      <td>40.799999</td>\n      <td>112.400002</td>\n      <td>108.500000</td>\n      <td>107.099998</td>\n      <td>59.299999</td>\n      <td>42.200001</td>\n      <td>24.600000</td>\n      <td>33.700001</td>\n      <td>30.000000</td>\n      <td>20.900000</td>\n      <td>31.900000</td>\n    </tr>\n  </tbody>\n</table>\n<p>252 rows × 15 columns</p>\n</div>"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# for data in classification_dataset_names:\n",
    "#     data = fetch_data(data)\n",
    "#     print(data.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numer of NANs:  0\n",
      "Dataset Information\n",
      "Rows: 252\n",
      "Columns: 12\n",
      "Number of classes: 176\n",
      "Continous columns: 12\n",
      "Binary columns: 0\n",
      "Categorical columns: 0\n",
      "-------------------------------------------------\n",
      "\u001B[1m\n",
      "\n",
      "    ----------------------------------------- 560_bodyfat -----------------------------------------\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ Warning: This copy of Interpretable AI software is for academic purposes only and not for commercial use.\n",
      "┌ Warning: Interpretable AI license expires soon: 2022-12-31T00:00:00. If you need to renew, please send us the following machine ID:\n",
      "└ 9ed379f63a363f5e759aa0e824692d130d8d8ad83880517bac52e890496b43cf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression CART mean performance:  0.5674612739375167\n",
      "\n",
      "\n",
      "Regression ORT performance:  0.5083570484134248\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orig = {}\n",
    "rules = []\n",
    "for classification_dataset in classification_dataset_names:\n",
    "    res_rul,rules,coefficients = experimentation(classification_dataset)\n",
    "    rules.append(rules)\n",
    "    orig.update(res_rul)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "data": {
      "text/plain": "     Density   Age  Weight  Height       Neck       Chest     Abdomen  \\\n0     1.0708  23.0  154.25   67.75  36.200001   93.099998   85.199997   \n1     1.0853  22.0  173.25   72.25  38.500000   93.599998   83.000000   \n2     1.0414  22.0  154.00   66.25  34.000000   95.800003   87.900002   \n3     1.0751  26.0  184.75   72.25  37.400002  101.800003   86.400002   \n4     1.0340  24.0  184.25   71.25  34.400002   97.300003  100.000000   \n..       ...   ...     ...     ...        ...         ...         ...   \n247   1.0736  70.0  134.25   67.00  34.900002   89.199997   83.599998   \n248   1.0236  72.0  201.00   69.75  40.900002  108.500000  105.000000   \n249   1.0328  72.0  186.75   66.00  38.900002  111.099998  111.500000   \n250   1.0399  72.0  190.75   70.50  38.900002  108.300003  101.300003   \n251   1.0271  74.0  207.50   70.00  40.799999  112.400002  108.500000   \n\n            Hip      Thigh       Knee      Ankle     Biceps    Forearm  \\\n0     94.500000  59.000000  37.299999  21.900000  32.000000  27.400000   \n1     98.699997  58.700001  37.299999  23.400000  30.500000  28.900000   \n2     99.199997  59.599998  38.900002  24.000000  28.799999  25.200001   \n3    101.199997  60.099998  37.299999  22.799999  32.400002  29.400000   \n4    101.900002  63.200001  42.200001  24.000000  32.200001  27.700001   \n..          ...        ...        ...        ...        ...        ...   \n247   88.800003  49.599998  34.799999  21.500000  25.600000  25.700001   \n248  104.500000  59.599998  40.799999  23.200001  35.200001  28.600000   \n249  101.699997  60.299999  37.299999  21.500000  31.299999  27.200001   \n250   97.800003  56.000000  41.599998  22.700001  30.500000  29.400000   \n251  107.099998  59.299999  42.200001  24.600000  33.700001  30.000000   \n\n         Wrist     target  \n0    17.100000  12.300000  \n1    18.200001   6.100000  \n2    16.600000  25.299999  \n3    18.200001  10.400000  \n4    17.700001  28.700001  \n..         ...        ...  \n247  18.500000  11.000000  \n248  20.100000  33.599998  \n249  18.000000  29.299999  \n250  19.799999  26.000000  \n251  20.900000  31.900000  \n\n[252 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Density</th>\n      <th>Age</th>\n      <th>Weight</th>\n      <th>Height</th>\n      <th>Neck</th>\n      <th>Chest</th>\n      <th>Abdomen</th>\n      <th>Hip</th>\n      <th>Thigh</th>\n      <th>Knee</th>\n      <th>Ankle</th>\n      <th>Biceps</th>\n      <th>Forearm</th>\n      <th>Wrist</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0708</td>\n      <td>23.0</td>\n      <td>154.25</td>\n      <td>67.75</td>\n      <td>36.200001</td>\n      <td>93.099998</td>\n      <td>85.199997</td>\n      <td>94.500000</td>\n      <td>59.000000</td>\n      <td>37.299999</td>\n      <td>21.900000</td>\n      <td>32.000000</td>\n      <td>27.400000</td>\n      <td>17.100000</td>\n      <td>12.300000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0853</td>\n      <td>22.0</td>\n      <td>173.25</td>\n      <td>72.25</td>\n      <td>38.500000</td>\n      <td>93.599998</td>\n      <td>83.000000</td>\n      <td>98.699997</td>\n      <td>58.700001</td>\n      <td>37.299999</td>\n      <td>23.400000</td>\n      <td>30.500000</td>\n      <td>28.900000</td>\n      <td>18.200001</td>\n      <td>6.100000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0414</td>\n      <td>22.0</td>\n      <td>154.00</td>\n      <td>66.25</td>\n      <td>34.000000</td>\n      <td>95.800003</td>\n      <td>87.900002</td>\n      <td>99.199997</td>\n      <td>59.599998</td>\n      <td>38.900002</td>\n      <td>24.000000</td>\n      <td>28.799999</td>\n      <td>25.200001</td>\n      <td>16.600000</td>\n      <td>25.299999</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0751</td>\n      <td>26.0</td>\n      <td>184.75</td>\n      <td>72.25</td>\n      <td>37.400002</td>\n      <td>101.800003</td>\n      <td>86.400002</td>\n      <td>101.199997</td>\n      <td>60.099998</td>\n      <td>37.299999</td>\n      <td>22.799999</td>\n      <td>32.400002</td>\n      <td>29.400000</td>\n      <td>18.200001</td>\n      <td>10.400000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0340</td>\n      <td>24.0</td>\n      <td>184.25</td>\n      <td>71.25</td>\n      <td>34.400002</td>\n      <td>97.300003</td>\n      <td>100.000000</td>\n      <td>101.900002</td>\n      <td>63.200001</td>\n      <td>42.200001</td>\n      <td>24.000000</td>\n      <td>32.200001</td>\n      <td>27.700001</td>\n      <td>17.700001</td>\n      <td>28.700001</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>247</th>\n      <td>1.0736</td>\n      <td>70.0</td>\n      <td>134.25</td>\n      <td>67.00</td>\n      <td>34.900002</td>\n      <td>89.199997</td>\n      <td>83.599998</td>\n      <td>88.800003</td>\n      <td>49.599998</td>\n      <td>34.799999</td>\n      <td>21.500000</td>\n      <td>25.600000</td>\n      <td>25.700001</td>\n      <td>18.500000</td>\n      <td>11.000000</td>\n    </tr>\n    <tr>\n      <th>248</th>\n      <td>1.0236</td>\n      <td>72.0</td>\n      <td>201.00</td>\n      <td>69.75</td>\n      <td>40.900002</td>\n      <td>108.500000</td>\n      <td>105.000000</td>\n      <td>104.500000</td>\n      <td>59.599998</td>\n      <td>40.799999</td>\n      <td>23.200001</td>\n      <td>35.200001</td>\n      <td>28.600000</td>\n      <td>20.100000</td>\n      <td>33.599998</td>\n    </tr>\n    <tr>\n      <th>249</th>\n      <td>1.0328</td>\n      <td>72.0</td>\n      <td>186.75</td>\n      <td>66.00</td>\n      <td>38.900002</td>\n      <td>111.099998</td>\n      <td>111.500000</td>\n      <td>101.699997</td>\n      <td>60.299999</td>\n      <td>37.299999</td>\n      <td>21.500000</td>\n      <td>31.299999</td>\n      <td>27.200001</td>\n      <td>18.000000</td>\n      <td>29.299999</td>\n    </tr>\n    <tr>\n      <th>250</th>\n      <td>1.0399</td>\n      <td>72.0</td>\n      <td>190.75</td>\n      <td>70.50</td>\n      <td>38.900002</td>\n      <td>108.300003</td>\n      <td>101.300003</td>\n      <td>97.800003</td>\n      <td>56.000000</td>\n      <td>41.599998</td>\n      <td>22.700001</td>\n      <td>30.500000</td>\n      <td>29.400000</td>\n      <td>19.799999</td>\n      <td>26.000000</td>\n    </tr>\n    <tr>\n      <th>251</th>\n      <td>1.0271</td>\n      <td>74.0</td>\n      <td>207.50</td>\n      <td>70.00</td>\n      <td>40.799999</td>\n      <td>112.400002</td>\n      <td>108.500000</td>\n      <td>107.099998</td>\n      <td>59.299999</td>\n      <td>42.200001</td>\n      <td>24.600000</td>\n      <td>33.700001</td>\n      <td>30.000000</td>\n      <td>20.900000</td>\n      <td>31.900000</td>\n    </tr>\n  </tbody>\n</table>\n<p>252 rows × 15 columns</p>\n</div>"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverse_transform(X, copy=None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [],
   "source": [
    "mean_weight = data['Height'].mean()\n",
    "mean_weight_std = data['Height'].std()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "data": {
      "text/plain": "71.91430601347143"
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.482*mean_weight_std+mean_weight"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "data": {
      "text/plain": "183.77"
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "183.77"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "data": {
      "text/plain": "          Density         Age      Weight      Height        Neck       Chest  \\\ncount  252.000000  252.000000  252.000000  252.000000  252.000000  252.000000   \nmean     1.055574   44.884921  178.924405   70.148810   37.992064  100.824206   \nstd      0.019031   12.602040   29.389160    3.662856    2.430913    8.430476   \nmin      0.995000   22.000000  118.500000   29.500000   31.100000   79.300003   \n25%      1.041400   35.750000  159.000000   68.250000   36.400002   94.350000   \n50%      1.054900   43.000000  176.500000   70.000000   38.000000   99.649998   \n75%      1.070400   54.000000  197.000000   72.250000   39.425001  105.375002   \nmax      1.108900   81.000000  363.149994   77.750000   51.200001  136.199997   \n\n          Abdomen         Hip       Thigh        Knee       Ankle      Biceps  \\\ncount  252.000000  252.000000  252.000000  252.000000  252.000000  252.000000   \nmean    92.555952   99.904762   59.405952   38.590476   23.102381   32.273413   \nstd     10.783077    7.164058    5.249952    2.411804    1.694894    3.021274   \nmin     69.400002   85.000000   47.200001   33.000000   19.100000   24.799999   \n25%     84.574999   95.500000   56.000000   36.975000   22.000000   30.200001   \n50%     90.950001   99.300003   59.000000   38.500000   22.799999   32.049999   \n75%     99.324997  103.525000   62.349999   39.925001   24.000000   34.325000   \nmax    148.100006  147.699997   87.300003   49.099998   33.900002   45.000000   \n\n          Forearm       Wrist      target  \ncount  252.000000  252.000000  252.000000  \nmean    28.663889   18.229762   19.150794  \nstd      2.020691    0.933585    8.368740  \nmin     21.000000   15.800000    0.000000  \n25%     27.299999   17.600000   12.475000  \n50%     28.700001   18.299999   19.200001  \n75%     30.000000   18.799999   25.299999  \nmax     34.900002   21.400000   47.500000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Density</th>\n      <th>Age</th>\n      <th>Weight</th>\n      <th>Height</th>\n      <th>Neck</th>\n      <th>Chest</th>\n      <th>Abdomen</th>\n      <th>Hip</th>\n      <th>Thigh</th>\n      <th>Knee</th>\n      <th>Ankle</th>\n      <th>Biceps</th>\n      <th>Forearm</th>\n      <th>Wrist</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>252.000000</td>\n      <td>252.000000</td>\n      <td>252.000000</td>\n      <td>252.000000</td>\n      <td>252.000000</td>\n      <td>252.000000</td>\n      <td>252.000000</td>\n      <td>252.000000</td>\n      <td>252.000000</td>\n      <td>252.000000</td>\n      <td>252.000000</td>\n      <td>252.000000</td>\n      <td>252.000000</td>\n      <td>252.000000</td>\n      <td>252.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1.055574</td>\n      <td>44.884921</td>\n      <td>178.924405</td>\n      <td>70.148810</td>\n      <td>37.992064</td>\n      <td>100.824206</td>\n      <td>92.555952</td>\n      <td>99.904762</td>\n      <td>59.405952</td>\n      <td>38.590476</td>\n      <td>23.102381</td>\n      <td>32.273413</td>\n      <td>28.663889</td>\n      <td>18.229762</td>\n      <td>19.150794</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.019031</td>\n      <td>12.602040</td>\n      <td>29.389160</td>\n      <td>3.662856</td>\n      <td>2.430913</td>\n      <td>8.430476</td>\n      <td>10.783077</td>\n      <td>7.164058</td>\n      <td>5.249952</td>\n      <td>2.411804</td>\n      <td>1.694894</td>\n      <td>3.021274</td>\n      <td>2.020691</td>\n      <td>0.933585</td>\n      <td>8.368740</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.995000</td>\n      <td>22.000000</td>\n      <td>118.500000</td>\n      <td>29.500000</td>\n      <td>31.100000</td>\n      <td>79.300003</td>\n      <td>69.400002</td>\n      <td>85.000000</td>\n      <td>47.200001</td>\n      <td>33.000000</td>\n      <td>19.100000</td>\n      <td>24.799999</td>\n      <td>21.000000</td>\n      <td>15.800000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.041400</td>\n      <td>35.750000</td>\n      <td>159.000000</td>\n      <td>68.250000</td>\n      <td>36.400002</td>\n      <td>94.350000</td>\n      <td>84.574999</td>\n      <td>95.500000</td>\n      <td>56.000000</td>\n      <td>36.975000</td>\n      <td>22.000000</td>\n      <td>30.200001</td>\n      <td>27.299999</td>\n      <td>17.600000</td>\n      <td>12.475000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.054900</td>\n      <td>43.000000</td>\n      <td>176.500000</td>\n      <td>70.000000</td>\n      <td>38.000000</td>\n      <td>99.649998</td>\n      <td>90.950001</td>\n      <td>99.300003</td>\n      <td>59.000000</td>\n      <td>38.500000</td>\n      <td>22.799999</td>\n      <td>32.049999</td>\n      <td>28.700001</td>\n      <td>18.299999</td>\n      <td>19.200001</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.070400</td>\n      <td>54.000000</td>\n      <td>197.000000</td>\n      <td>72.250000</td>\n      <td>39.425001</td>\n      <td>105.375002</td>\n      <td>99.324997</td>\n      <td>103.525000</td>\n      <td>62.349999</td>\n      <td>39.925001</td>\n      <td>24.000000</td>\n      <td>34.325000</td>\n      <td>30.000000</td>\n      <td>18.799999</td>\n      <td>25.299999</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.108900</td>\n      <td>81.000000</td>\n      <td>363.149994</td>\n      <td>77.750000</td>\n      <td>51.200001</td>\n      <td>136.199997</td>\n      <td>148.100006</td>\n      <td>147.699997</td>\n      <td>87.300003</td>\n      <td>49.099998</td>\n      <td>33.900002</td>\n      <td>45.000000</td>\n      <td>34.900002</td>\n      <td>21.400000</td>\n      <td>47.500000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "data": {
      "text/plain": "70.14880952380952"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Height'].mean()\n",
    "data['Height'].mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "[[21.088015568971308,\n  array([ 2.29873927,  2.70200269, -0.65604061, -1.058245  ,  1.6474585 ,\n          1.50942998,  1.48509101, -0.58331955, -0.20032325, -0.63300611,\n          0.56157606, -2.32322485, -6.26982326, -3.08569504, -0.02399061,\n         -4.84097242, -0.33093284,  1.51567005])],\n [24.194909519747863,\n  array([ 1.84360066,  2.57889212, -0.52256208, -1.01931442,  1.62638597,\n          1.15305536,  1.1928441 , -0.49192767, -0.32785958, -0.4906077 ,\n          0.39817844, -1.87368126, -9.64664026, -1.92099746, -6.1685685 ,\n         -0.94540549, -8.8084112 , -2.06283972])],\n [24.194909519747863,\n  array([ 1.84360066,  2.57889212, -0.52256208, -1.01931442,  1.62638597,\n          1.15305536,  1.1928441 , -0.49192767, -0.32785958, -0.4906077 ,\n          0.39817844, -1.87368126, -9.64664026, -1.92099746, -6.1685685 ,\n         -0.94540549, -8.8084112 , -2.06283972])]]"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefficients"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'(feature['Weight'] >= 0.165) & (feature['Age'] < -0.529) & (feature['Height'] >= 0.482)'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "[Index(['Age', 'Weight', 'Height', 'Neck', 'Chest', 'Hip', 'Thigh', 'Knee',\n        'Ankle', 'Biceps', 'Forearm', 'Wrist',\n        '(feature['Chest'] < 0.107) & (feature['Chest'] < -0.772) & (feature['Thigh'] < -0.11)',\n        '(feature['Chest'] < 0.107) & (feature['Chest'] < -0.772) & (feature['Thigh'] >= -0.11)',\n        '(feature['Chest'] < 0.107) & (feature['Chest'] >= -0.772) & (feature['Height'] < 0.418)',\n        '(feature['Chest'] < 0.107) & (feature['Chest'] >= -0.772) & (feature['Height'] >= 0.418)',\n        '(feature['Chest'] >= 0.107) & (feature['Chest'] < 1.471) & (feature['Height'] < 1.282)',\n        '(feature['Chest'] >= 0.107) & (feature['Chest'] >= 1.471) & (feature['Height'] >= -1.086)'],\n       dtype='object'),\n Index(['Age', 'Weight', 'Height', 'Neck', 'Chest', 'Hip', 'Thigh', 'Knee',\n        'Ankle', 'Biceps', 'Forearm', 'Wrist',\n        '(feature['Weight'] < 0.165) & (feature['Chest'] < -0.743) & (feature['Thigh'] < 0.146)',\n        '(feature['Weight'] < 0.165) & (feature['Chest'] >= -0.743) & (feature['Height'] < -0.414)',\n        '(feature['Weight'] < 0.165) & (feature['Chest'] >= -0.743) & (feature['Height'] >= -0.414)',\n        '(feature['Weight'] >= 0.165) & (feature['Age'] < -0.529) & (feature['Height'] < 0.482)',\n        '(feature['Weight'] >= 0.165) & (feature['Age'] < -0.529) & (feature['Height'] >= 0.482)',\n        '(feature['Weight'] >= 0.165) & (feature['Age'] >= -0.529) & (feature['Hip'] < 1.645)'],\n       dtype='object'),\n Index(['Age', 'Weight', 'Height', 'Neck', 'Chest', 'Hip', 'Thigh', 'Knee',\n        'Ankle', 'Biceps', 'Forearm', 'Wrist',\n        '(feature['Weight'] < 0.165) & (feature['Chest'] < -0.743) & (feature['Thigh'] < 0.146)',\n        '(feature['Weight'] < 0.165) & (feature['Chest'] >= -0.743) & (feature['Height'] < -0.414)',\n        '(feature['Weight'] < 0.165) & (feature['Chest'] >= -0.743) & (feature['Height'] >= -0.414)',\n        '(feature['Weight'] >= 0.165) & (feature['Age'] < -0.529) & (feature['Height'] < 0.482)',\n        '(feature['Weight'] >= 0.165) & (feature['Age'] < -0.529) & (feature['Height'] >= 0.482)',\n        '(feature['Weight'] >= 0.165) & (feature['Age'] >= -0.529) & (feature['Hip'] < 1.645)'],\n       dtype='object'),\n [...]]"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4ead8e38b31a422c903d4cf545dc66bf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: error initializing stdin in uv_pipe_open: inappropriate ioctl for device (ENOTTY -25)\n",
      "ERROR: ERROR: error initializing stdin in uv_pipe_open: inappropriate ioctl for device (ENOTTY -25)\n",
      "error initializing stdin in uv_pipe_open: inappropriate ioctl for device (ENOTTY -25)\n",
      "ERROR: error initializing stdin in uv_pipe_open: inappropriate ioctl for device (ENOTTY -25)ERROR: error initializing stdin in uv_pipe_open: inappropriate ioctl for device (ENOTTY -25)\n",
      "\n",
      "ERROR: error initializing stdin in uv_pipe_open: inappropriate ioctl for device (ENOTTY -25)\n",
      "ERROR: error initializing stdin in uv_pipe_open: inappropriate ioctl for device (ENOTTY -25)\n",
      "ERROR: error initializing stdin in uv_pipe_open: inappropriate ioctl for device (ENOTTY -25)\n"
     ]
    },
    {
     "ename": "BrokenProcessPool",
     "evalue": "A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31m_RemoteTraceback\u001B[0m                          Traceback (most recent call last)",
      "\u001B[0;31m_RemoteTraceback\u001B[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Library/Python/3.9/site-packages/joblib/externals/loky/process_executor.py\", line 391, in _process_worker\n    call_item = call_queue.get(block=True, timeout=timeout)\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py\", line 122, in get\n    return _ForkingPickler.loads(res)\n  File \"/Users/paulchristophroeseler/Dropbox (MIT)/PycharmProjects/pythonProject/ORRFA-2/ex_func.py\", line 3, in <module>\n    from interpretableai import iai\n  File \"/Library/Python/3.9/site-packages/interpretableai/iai.py\", line 36, in <module>\n    _Main = iai_run_julia_setup()\n  File \"/Library/Python/3.9/site-packages/interpretableai/installation.py\", line 106, in iai_run_julia_setup\n    julia.Julia(**kwargs)\n  File \"/Library/Python/3.9/site-packages/julia/core.py\", line 696, in __init__\n    self.__julia = Julia(*args, **kwargs)\n  File \"/Library/Python/3.9/site-packages/julia/core.py\", line 468, in __init__\n    jlinfo = JuliaInfo.load(runtime)\n  File \"/Library/Python/3.9/site-packages/julia/juliainfo.py\", line 87, in load\n    raise subprocess.CalledProcessError(\nsubprocess.CalledProcessError: Command '['/Users/paulchristophroeseler/Library/Application Support/InterpretableAI/julia/1.8.2/Julia-1.8.app/Contents/Resources/julia/bin/julia', '-e', '...']' returned non-zero exit status 1.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mBrokenProcessPool\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [9], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mjoblib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m delayed\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtqdm\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tqdm\n\u001B[0;32m----> 3\u001B[0m res_rul \u001B[38;5;241m=\u001B[39m \u001B[43mProgressParallel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m8\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexperimentation\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mregression_dataset_names\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Dropbox (MIT)/PycharmProjects/pythonProject/ORRFA-2/ex_func.py:37\u001B[0m, in \u001B[0;36mProgressParallel.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     36\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m tqdm(disable\u001B[38;5;241m=\u001B[39m\u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_use_tqdm, total\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_total) \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pbar:\n\u001B[0;32m---> 37\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mParallel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Python/3.9/site-packages/joblib/parallel.py:1098\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1095\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m   1097\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[0;32m-> 1098\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mretrieve\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;66;03m# Make sure that we get a last message telling us we are done\u001B[39;00m\n\u001B[1;32m   1100\u001B[0m elapsed_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_start_time\n",
      "File \u001B[0;32m/Library/Python/3.9/site-packages/joblib/parallel.py:975\u001B[0m, in \u001B[0;36mParallel.retrieve\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    973\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    974\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msupports_timeout\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m--> 975\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output\u001B[38;5;241m.\u001B[39mextend(\u001B[43mjob\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    976\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    977\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output\u001B[38;5;241m.\u001B[39mextend(job\u001B[38;5;241m.\u001B[39mget())\n",
      "File \u001B[0;32m/Library/Python/3.9/site-packages/joblib/_parallel_backends.py:567\u001B[0m, in \u001B[0;36mLokyBackend.wrap_future_result\u001B[0;34m(future, timeout)\u001B[0m\n\u001B[1;32m    564\u001B[0m \u001B[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001B[39;00m\n\u001B[1;32m    565\u001B[0m \u001B[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001B[39;00m\n\u001B[1;32m    566\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 567\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfuture\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    568\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m CfTimeoutError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    569\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTimeoutError\u001B[39;00m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py:445\u001B[0m, in \u001B[0;36mFuture.result\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    443\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n\u001B[1;32m    444\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;241m==\u001B[39m FINISHED:\n\u001B[0;32m--> 445\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__get_result\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    446\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    447\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTimeoutError\u001B[39;00m()\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py:390\u001B[0m, in \u001B[0;36mFuture.__get_result\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    388\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception:\n\u001B[1;32m    389\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 390\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception\n\u001B[1;32m    391\u001B[0m     \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    392\u001B[0m         \u001B[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001B[39;00m\n\u001B[1;32m    393\u001B[0m         \u001B[38;5;28mself\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[0;31mBrokenProcessPool\u001B[0m: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable."
     ]
    }
   ],
   "source": [
    "# from joblib import delayed\n",
    "# from tqdm import tqdm\n",
    "# res_rul = ProgressParallel(n_jobs=8)(delayed(experimentation)(data) for data in regression_dataset_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result = {}\n",
    "for d in res_rul:\n",
    "    result.update(d)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import os\n",
    "# files = os.listdir('C:/Users/paulr/PycharmProjects/pythonProject/ORRFA-2/')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# list_of_dfs = []\n",
    "# for file in files:\n",
    "#     if file.endswith('pickle'):\n",
    "#         with open(file, 'rb') as handle:\n",
    "#             b = pickle.load(handle)\n",
    "#             # df = pd.concat({k:json_normalize(v, 'scores', ['best']) for k,v in d.items()})\n",
    "#             # df = df.reset_index(level=1, drop=True).rename_axis('names').reset_index()\n",
    "# #             list_of_dfs.append(b)\n",
    "# big_df = pd.concat(list_of_dfs, ignore_index=True)#ignore_index to reset index of big_df\n",
    "# big_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# k = pd.DataFrame(result,index=[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#k.to_csv('results/results_gridsearch.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "g"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('results_regression_depth4.pkl', 'wb') as f:\n",
    "    pickle.dump(result, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k = pd.DataFrame(result,index=[0])\n",
    "k = k.stack(level=2).sort_index()\n",
    "k = k.stack(level=2).sort_index()\n",
    "k = k.swaplevel(axis=1)\n",
    "k = k.droplevel(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "k.mean(level=0,axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "k.to_csv('results_regression_depth3.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# k.to_csv('result_girdsearch.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "k.swaplevel(axis=0).mean(level=0).mean(level=0,axis=1).iloc[9].sort_values(ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "k.swaplevel(axis=0).mean(level=0).mean(level=0,axis=1).iloc[1].sort_values(ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t=k.mean(level=0,axis=1)\n",
    "t = t.mean(axis=0)\n",
    "t.sort_values(ascending = False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = k.swaplevel(axis=1)\n",
    "y = y.var(level=0,axis=1)\n",
    "y = y.mean(axis=0)\n",
    "good_tests = y[y < 0.01].index\n",
    "good = list(good_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vaild_results = k.iloc[:,k.columns.isin(good, level=1)]\n",
    "vaild_results=vaild_results.mean(level=0,axis=1)\n",
    "vaild_results.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a935b482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(nrows = 5, ncols = 4, gridspec_kw = {\"hspace\": 0.25})\n",
    "import seaborn as sns\n",
    "fig.set_size_inches(30, 25)\n",
    "iteration = 0\n",
    "\n",
    "for m in range(5):\n",
    "    for j in range(4):\n",
    "\n",
    "        dataset = classification_dataset_names[:20][iteration]\n",
    "\n",
    "        columns = [i for i in k.columns if dataset in i]\n",
    "        sns.boxplot(k[columns], ax = ax[m, j])\n",
    "\n",
    "        ax[m, j].set_title(dataset)\n",
    "\n",
    "        ax[m, j].set_xticklabels(['CART Rules', \"OCT Rules\", \"Logistic Regression\", \"RuleFit\", \"ORRFA\"])\n",
    "\n",
    "        iteration += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94a02e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "fig, ax = plt.subplots()\n",
    "sns.boxplot(data = performance_by_iter)\n",
    "fig.set_size_inches(20, 10)\n",
    "ax.set_xticklabels(performance_by_iter.columns.values)\n",
    "# ax.set_ylim(0.93, 0.995)\n",
    "ax.tick_params(rotation = 0, labelsize = 14)\n",
    "ax.set_ylabel(\"Accuracy\", fontsize = 14)\n",
    "ax.set_title(\"Accuracy of Logistic Regression, RuleFit and ORRFA\", fontsize = 15)\n",
    "# ax.set_ylabel()\n",
    "plt.savefig('Benchmark ORRFA.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pmlb import fetch_data, classification_dataset_names"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "res_rul = ProgressParallel(n_jobs=15)(delayed(experimentation)(data) for data in regression_dataset_names)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classification_dataset = regression_dataset_names[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "res_rul = {}\n",
    "names = ['Reg-CART','CART','ORT','OCT','ORT-H','OCT-H','ORT+ORT-H','OCT+OCT-H']\n",
    "algorithms = ['LR','LS','RG']\n",
    "pipelines = [LR_pipeline,LS_pipeline,RG_pipeline]\n",
    "\n",
    "iters = 5\n",
    "df = fetch_data(classification_dataset)\n",
    "print('Numer of NANs: ',df.isna().sum().sum())\n",
    "y, X = corr_data_for(df)\n",
    "\n",
    "del df\n",
    "\n",
    "print(color.BOLD + '\\n\\n    ----------------------------------------- {} -----------------------------------------'.format(classification_dataset) + color.END)\n",
    "for it in range(iters):\n",
    "    X_train, X_test, y_train, y_test = split_function(y,X,it)\n",
    "    col_len = len(X_train.columns)\n",
    "    factors = [0.5,1,1.2,1.4,1.6,1.8,2,2.5,3]\n",
    "\n",
    "    models, performance = generate_tree(X_train, y_train, X_test, y_test, n_num=1, feat_size=len(X.columns),  max_iter_hy=2,sub_paths=True,depth_grid=range(3,4), depth_grid_hy=range(1,3), complexity_bi = 0.001, complexity_hy=0.001,  Reg_CART=True, ORT=True, ORT_H=False, Clas_CART=False, OCT=False, OCT_H=False)\n",
    "\n",
    "    for perf,name in zip(performance,names):\n",
    "        if not not perf:\n",
    "            res_rul[(classification_dataset,name,it,1)] = sum(perf) / len(perf)\n",
    "\n",
    "    act_name = []\n",
    "    act_rules = []\n",
    "    for model,name in zip(models,names):\n",
    "        if (all(model)) & (not not model) & (None not in model):\n",
    "            act_name.append(name)\n",
    "            act_rules.append(model)\n",
    "\n",
    "    datasets = gen_train_and_test_features(act_rules ,act_name , X_train, X_test)\n",
    "\n",
    "    for model in datasets.keys():\n",
    "        X_train_rules_and_features, X_test_rules_and_features = datasets[model][0]\n",
    "        X_train_only_rules, X_test_only_rules = datasets[model][1]\n",
    "\n",
    "        for algorithm,pipeline in zip(algorithms,pipelines):\n",
    "            res_rul[(classification_dataset,model + f'_{algorithm}_rules',it,'all')] = pipeline(X_train_only_rules, X_test_only_rules, y_train, y_test)\n",
    "            res_rul[(classification_dataset,model + f'_{algorithm}_rules_and_features',it,'all')] = pipeline(X_train_rules_and_features, X_test_rules_and_features, y_train, y_test)\n",
    "\n",
    "        for fact in factors:\n",
    "            if (round(len(X_train_rules_and_features.columns)*fact) <= X_train.shape[0]) & (round(col_len*fact) <= len(X_train_rules_and_features.columns)):\n",
    "                min_feat_rule = round(col_len*fact)\n",
    "\n",
    "                if (round(col_len*fact) > len(X_train_only_rules.columns)) & (fact != 0.5):\n",
    "                    len_rule = 1\n",
    "                    min_rule = len(X_train_only_rules.columns)\n",
    "                else:\n",
    "                    len_rule = fact\n",
    "                    min_rule = min(round(col_len*fact),len(X_train_only_rules.columns))\n",
    "\n",
    "                cols = SelectKBest(k=min_feat_rule).fit(X_train_rules_and_features,y_train).get_feature_names_out()\n",
    "                cols_rule = SelectKBest(k=min_rule).fit(X_train_only_rules,y_train).get_feature_names_out()\n",
    "\n",
    "            else:\n",
    "                 continue\n",
    "\n",
    "            for algorithm,pipeline in zip(algorithms,pipelines):\n",
    "                res_rul[(classification_dataset,model + f'_{algorithm}_rules',it,len_rule)] = pipeline(X_train_only_rules[cols_rule], X_test_only_rules[cols_rule], y_train, y_test)\n",
    "                res_rul[(classification_dataset,model + f'_{algorithm}_rules_and_features',it,fact)] = pipeline(X_train_rules_and_features[cols], X_test_rules_and_features[cols], y_train, y_test)\n",
    "\n",
    "    for algorithm,pipeline in zip(algorithms,pipelines):\n",
    "        res_rul[(classification_dataset,algorithm,it,1)] = pipeline(X_train, X_test, y_train, y_test)\n",
    "    del X_train, X_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TARGET_NAME = 'target'\n",
    "feat_names = [col for col in df.columns if col!=TARGET_NAME]\n",
    "types = [get_feature_type(df[col], include_binary=True) for col in feat_names]\n",
    "col = pd.DataFrame(feat_names,types)\n",
    "num_col = col[col.index == 'continuous']\n",
    "bin_col = col[col.index == 'binary']\n",
    "cat_col = col[col.index == 'categorical']\n",
    "cat_col = cat_col[0].tolist()\n",
    "dummy_col = pd.get_dummies(data=df, columns=cat_col)\n",
    "add_col = dummy_col.shape[1] - df.shape[1]\n",
    "\n",
    "if (add_col < df.shape[0] *0.3) & (dummy_col.shape[1] <  df.shape[0]) & (df.shape[0] < 10000) & (df.shape[1] < 100):\n",
    "    df = dummy_col\n",
    "    df.columns = df.columns.str.replace('.','_',regex=True)\n",
    "    y = df['target']\n",
    "    X = df.loc[:, df.columns != 'target']\n",
    "    del df\n",
    "    rows_data, columns_data = X.shape\n",
    "    print('Dataset Information')\n",
    "    print('Rows:',rows_data,)\n",
    "    print('Columns:',columns_data)\n",
    "    print('Number of classes:',y.nunique())\n",
    "    print('Continous columns:', len(num_col))\n",
    "    print('Binary columns:', len(bin_col))\n",
    "    print('Categorical columns:',len(cat_col))\n",
    "    print('-------------------------------------------------')\n",
    "    else:\n",
    "        del df\n",
    "        return pd.DataFrame, pd.DataFrame\n",
    "    return y, X"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
