{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d1d48a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import linecache\n",
    "from collections import Counter\n",
    "import os\n",
    "import tracemalloc\n",
    "\n",
    "def display_top(snapshot, key_type='lineno', limit=3):\n",
    "    snapshot = snapshot.filter_traces((\n",
    "        tracemalloc.Filter(False, \"<frozen importlib._bootstrap>\"),\n",
    "        tracemalloc.Filter(False, \"<unknown>\"),\n",
    "    ))\n",
    "    top_stats = snapshot.statistics(key_type)\n",
    "\n",
    "    print(\"Top %s lines\" % limit)\n",
    "    for index, stat in enumerate(top_stats[:limit], 1):\n",
    "        frame = stat.traceback[0]\n",
    "        # replace \"/path/to/module/file.py\" with \"module/file.py\"\n",
    "        filename = os.sep.join(frame.filename.split(os.sep)[-2:])\n",
    "        print(\"#%s: %s:%s: %.1f KiB\"\n",
    "              % (index, filename, frame.lineno, stat.size / 1024))\n",
    "        line = linecache.getline(frame.filename, frame.lineno).strip()\n",
    "        if line:\n",
    "            print('    %s' % line)\n",
    "\n",
    "    other = top_stats[limit:]\n",
    "    if other:\n",
    "        size = sum(stat.size for stat in other)\n",
    "        print(\"%s other: %.1f KiB\" % (len(other), size / 1024))\n",
    "    total = sum(stat.size for stat in top_stats)\n",
    "    print(\"Total allocated size: %.1f KiB\" % (total / 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7306a81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pauls_functions_advanced_v3 import *\n",
    "from experiment_functions import *\n",
    "import pandas as pd\n",
    "from pmlb import fetch_data, classification_dataset_names\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from joblib import Parallel\n",
    "\n",
    "class ProgressParallel(Parallel):\n",
    "    def __init__(self, use_tqdm=True, total=None, *args, **kwargs):\n",
    "        self._use_tqdm = use_tqdm\n",
    "        self._total = total\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        with tqdm(disable=not self._use_tqdm, total=self._total) as self._pbar:\n",
    "            return Parallel.__call__(self, *args, **kwargs)\n",
    "\n",
    "    def print_progress(self):\n",
    "        if self._total is None:\n",
    "            self._pbar.total = self.n_dispatched_tasks\n",
    "        self._pbar.n = self.n_completed_tasks\n",
    "        self._pbar.refresh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_feature_type(x, include_binary=False):\n",
    "    x.dropna(inplace=True)\n",
    "    if not check_if_all_integers(x):\n",
    "        return 'continuous'\n",
    "    else:\n",
    "        if x.nunique() > 10:\n",
    "            return 'continuous'\n",
    "        if include_binary:\n",
    "            if x.nunique() == 2:\n",
    "                return 'binary'\n",
    "        return 'categorical'\n",
    "\n",
    "def get_target_type(x, include_binary=False):\n",
    "    x.dropna(inplace=True)\n",
    "    if x.dtype=='float64':\n",
    "        return 'continuous'\n",
    "    elif x.dtype=='int64':\n",
    "        if include_binary:\n",
    "            if x.nunique() == 2:\n",
    "                return 'binary'\n",
    "        return 'categorical'\n",
    "    else:\n",
    "        raise ValueError(\"Error getting type\")\n",
    "\n",
    "def check_if_all_integers(x):\n",
    "    \"check a pandas.Series is made of all integers.\"\n",
    "    return all(float(i).is_integer() for i in x.unique())\n",
    "def corr_data_for(df):\n",
    "    TARGET_NAME = 'target'\n",
    "    feat_names = [col for col in df.columns if col!=TARGET_NAME]\n",
    "    types = [get_feature_type(df[col], include_binary=True) for col in feat_names]\n",
    "    col = pd.DataFrame(feat_names,types)\n",
    "    num_col = col[col.index == 'continuous']\n",
    "    bin_col = col[col.index == 'binary']\n",
    "    cat_col = col[col.index == 'categorical']\n",
    "    cat_col = cat_col[0].tolist()\n",
    "    dummy_col = pd.get_dummies(data=df, columns=cat_col)\n",
    "    add_col = dummy_col.shape[1] - df.shape[1]\n",
    "    if (add_col < df.shape[0] *0.3) & (dummy_col.shape[1] <  df.shape[0]):\n",
    "        df = dummy_col\n",
    "        df.columns = df.columns.str.replace('.','_',regex=True)\n",
    "    else:\n",
    "        del df\n",
    "        df = pd.DataFrame()\n",
    "    return df, num_col, bin_col, cat_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for data in classification_dataset_names:\n",
    "#     data = fetch_data(data)\n",
    "#     print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classification_dataset_names = classification_dataset_names[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def experimentation(classification_dataset):\n",
    "    iters=5\n",
    "    res_rul = {}\n",
    "    sc = StandardScaler()\n",
    "    names = ['Reg-CART','CART','ORT','OCT','ORT-H','OCT-H','ORT+ORT-H','OCT+OCT-H']\n",
    "    df = fetch_data(classification_dataset)\n",
    "    if df.shape[0] > 50000:\n",
    "        return\n",
    "    if df.shape[1] > 100:\n",
    "        return\n",
    "    df, num_col, bin_col, cat_col = corr_data_for(df)\n",
    "    if df.empty:\n",
    "        return\n",
    "    y = df['target']\n",
    "    X = df.loc[:, df.columns != 'target']\n",
    "    #performance_by_iter = pd.DataFrame(columns = [\"Logistic Regression\", \"CART_rules\", \"OCT_rules\", \"OCTH_rules\", \"CART_rules_and_features\", \"OCT_rules_and_features\", \"OCTH_rules_and_features\"], index = np.arange(0, iters))\n",
    "    print(color.BOLD + '\\n\\n    ----------------------------------------- {} -----------------------------------------'.format(classification_dataset) + color.END)\n",
    "    rows_data, columns_data = X.shape\n",
    "    print('Dataset Information')\n",
    "    print('Rows:',rows_data,)\n",
    "    print('Columns:',columns_data)\n",
    "    print('Number of classes:',y.nunique())\n",
    "    print('Continous columns:', len(num_col))\n",
    "    print('Binary columns:', len(bin_col))\n",
    "    print('Categorical columns:',len(cat_col))\n",
    "    print('-------------------------------------------------')\n",
    "    for it in range(iters):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = it, stratify=y)\n",
    "        X_col = X_train.columns\n",
    "        col_len = len(X_col)\n",
    "        X_test.name = \"X_test\"\n",
    "        X_train.name = \"X_train\"\n",
    "        X_train = sc.fit_transform(X_train)\n",
    "        X_test = sc.transform(X_test)\n",
    "        X_train = pd.DataFrame(X_train,columns=X_col)\n",
    "        X_test = pd.DataFrame(X_test,columns=X_col)\n",
    "        factors = [round(col_len*0.5),col_len,round(col_len*1.2),round(col_len*1.4),round(col_len*1.6),round(col_len*1.8),round(col_len*2),round(col_len*2.5),round(col_len*3)]\n",
    "        factors_name = [0.5,1,1.2,1.4,1.6,1.8,2,2.5,3]\n",
    "\n",
    "\n",
    "\n",
    "        models, performance = generate_tree(X_train, y_train, X_test, y_test, n_num=1, feat_size=len(X.columns),  max_iter_hy=2,sub_paths=False,depth_grid=range(1,7), depth_grid_hy=range(1,3), complexity_bi = 0.001, complexity_hy=0.001,  Reg_CART=False, ORT=False, ORT_H=False, Clas_CART=True, OCT=True, OCT_H=False)\n",
    "        for perf,name in zip(performance,names):\n",
    "            if not not perf:\n",
    "                res_rul[(classification_dataset,name,it,1)] = sum(perf) / len(perf)\n",
    "\n",
    "        act_name = []\n",
    "        act_rules = []\n",
    "        for model,name in zip(models,names):\n",
    "            if not not model:\n",
    "                act_name += [name]\n",
    "                act_rules += [model]\n",
    "\n",
    "        datasets = gen_train_and_test_features(act_rules ,act_name , X_train, X_test)\n",
    "        for model in datasets.keys():\n",
    "            print(model)\n",
    "            X_train_rules_and_features, X_test_rules_and_features = datasets[model][0]\n",
    "            X_train_only_rules, X_test_only_rules = datasets[model][1]\n",
    "            print(len(X_train_rules_and_features.columns))\n",
    "            for len_c,fac_name in zip(factors,factors_name):\n",
    "                if len_c > len(X_train_only_rules.columns):\n",
    "                    min_len = len(X_train_only_rules.columns)\n",
    "                    min_name = 1\n",
    "                else:\n",
    "                    min_len = len_c\n",
    "                    min_name = fac_name\n",
    "                if (len_c <= X_train.shape[0]) & (len_c <= len(X_train_rules_and_features.columns)):\n",
    "                    cols = SelectKBest(k=len_c).fit(X_train_rules_and_features,y_train).get_feature_names_out()\n",
    "                    X_train_rules_features = X_train_rules_and_features[cols]\n",
    "                    X_test_rules_features = X_test_rules_and_features[cols]\n",
    "\n",
    "                    cols_1 = SelectKBest(k=min_len).fit(X_train_only_rules,y_train).get_feature_names_out()\n",
    "                    X_train_rules = X_train_only_rules[cols_1]\n",
    "                    X_test_rules = X_test_only_rules[cols_1]\n",
    "\n",
    "                    only_rules_acc = log_regression_pipeline(X_train_rules, X_test_rules, y_train, y_test)\n",
    "                    rules_and_features_acc = log_regression_pipeline(X_train_rules_features, X_test_rules_features, y_train, y_test)\n",
    "                    res_rul[(classification_dataset,model + \"_LG_rules\",it,min_name)] = only_rules_acc\n",
    "                    res_rul[(classification_dataset,model + \"_LG_rules_and_features\",it,fac_name)] = rules_and_features_acc\n",
    "\n",
    "                    only_rules_acc_SVM = SVM_pipeline(X_train_rules, X_test_rules, y_train, y_test)\n",
    "                    rules_and_features_acc_SVM = SVM_pipeline(X_train_rules_features, X_test_rules_features, y_train, y_test)\n",
    "                    res_rul[(classification_dataset,model + \"_SVM_rules\",it,min_name)] = only_rules_acc_SVM\n",
    "                    res_rul[(classification_dataset,model + \"_SVM_rules_and_features\",it,fac_name)] = rules_and_features_acc_SVM\n",
    "\n",
    "                    only_rules_acc_NB = NB_pipeline(X_train_rules, X_test_rules, y_train, y_test)\n",
    "                    rules_and_features_acc_NB = NB_pipeline(X_train_rules_features, X_test_rules_features, y_train, y_test)\n",
    "                    res_rul[(classification_dataset,model + \"_NB_rules\",it,min_name)] = only_rules_acc_NB\n",
    "                    res_rul[(classification_dataset,model + \"_NB_rules_and_features\",it,fac_name)] = rules_and_features_acc_NB\n",
    "\n",
    "                    only_rules_acc_KNN = KNN_pipeline(X_train_rules, X_test_rules, y_train, y_test)\n",
    "                    rules_and_features_acc_KNN = KNN_pipeline(X_train_rules_features, X_test_rules_features, y_train, y_test)\n",
    "                    res_rul[(classification_dataset,model + \"_KNN_rules\",it,min_name)] = only_rules_acc_KNN\n",
    "                    res_rul[(classification_dataset,model + \"_KNN_rules_and_features\",it,fac_name)] = rules_and_features_acc_KNN\n",
    "                else:\n",
    "                     continue\n",
    "\n",
    "        res_rul[(classification_dataset,'Logistic_Regression',it,1)] = log_regression_pipeline(X_train, X_test, y_train, y_test)\n",
    "\n",
    "        res_rul[(classification_dataset,\"Support Vector Machine\",it,1)] = SVM_pipeline(X_train, X_test, y_train, y_test)\n",
    "\n",
    "        res_rul[(classification_dataset,\"Naive Bayes\",it,1)] = NB_pipeline(X_train, X_test, y_train, y_test)\n",
    "\n",
    "        res_rul[(classification_dataset,\"K-Nearest-Neighbor\",it,1)] = KNN_pipeline(X_train, X_test, y_train, y_test)\n",
    "        with open(classification_dataset + '.pickle', 'wb') as handle:\n",
    "            pickle.dump(res_rul, handle)\n",
    "    return res_rul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "904b38f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tracemalloc.start()\n",
    "#\n",
    "# counts = Counter()\n",
    "#\n",
    "# experimentation(classification_dataset_names[0])\n",
    "#\n",
    "# snapshot = tracemalloc.take_snapshot()\n",
    "# display_top(snapshot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]ERROR: error initializing stdin in uv_pipe_open: inappropriate ioctl for device (ENOTTY -25)\n",
      "ERROR: error initializing stdin in uv_pipe_open: inappropriate ioctl for device (ENOTTY -25)\n",
      "ERROR: error initializing stdin in uv_pipe_open: inappropriate ioctl for device (ENOTTY -25)\n",
      "ERROR: error initializing stdin in uv_pipe_open: inappropriate ioctl for device (ENOTTY -25)\n",
      "ERROR: error initializing stdin in uv_pipe_open: inappropriate ioctl for device (ENOTTY -25)\n",
      "ERROR: error initializing stdin in uv_pipe_open: inappropriate ioctl for device (ENOTTY -25)\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.20it/s]\n"
     ]
    },
    {
     "ename": "BrokenProcessPool",
     "evalue": "A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31m_RemoteTraceback\u001B[0m                          Traceback (most recent call last)",
      "\u001B[0;31m_RemoteTraceback\u001B[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Library/Python/3.9/site-packages/joblib/externals/loky/process_executor.py\", line 391, in _process_worker\n    call_item = call_queue.get(block=True, timeout=timeout)\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py\", line 122, in get\n    return _ForkingPickler.loads(res)\n  File \"/Users/paulchristophroeseler/Dropbox (MIT)/PycharmProjects/pythonProject/ORRFA-2/pauls_functions_advanced_v3.py\", line 3, in <module>\n    from interpretableai import iai\n  File \"/Library/Python/3.9/site-packages/interpretableai/iai.py\", line 36, in <module>\n    _Main = iai_run_julia_setup()\n  File \"/Library/Python/3.9/site-packages/interpretableai/installation.py\", line 106, in iai_run_julia_setup\n    julia.Julia(**kwargs)\n  File \"/Library/Python/3.9/site-packages/julia/core.py\", line 696, in __init__\n    self.__julia = Julia(*args, **kwargs)\n  File \"/Library/Python/3.9/site-packages/julia/core.py\", line 468, in __init__\n    jlinfo = JuliaInfo.load(runtime)\n  File \"/Library/Python/3.9/site-packages/julia/juliainfo.py\", line 87, in load\n    raise subprocess.CalledProcessError(\nsubprocess.CalledProcessError: Command '['/Users/paulchristophroeseler/Library/Application Support/InterpretableAI/julia/1.8.2/Julia-1.8.app/Contents/Resources/julia/bin/julia', '-e', '...']' returned non-zero exit status 1.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mBrokenProcessPool\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [31], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mjoblib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m delayed\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtqdm\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tqdm\n\u001B[0;32m----> 3\u001B[0m res_rul \u001B[38;5;241m=\u001B[39m \u001B[43mProgressParallel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m6\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexperimentation\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mclassification_dataset_names\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn [25], line 12\u001B[0m, in \u001B[0;36mProgressParallel.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m tqdm(disable\u001B[38;5;241m=\u001B[39m\u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_use_tqdm, total\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_total) \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pbar:\n\u001B[0;32m---> 12\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mParallel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Python/3.9/site-packages/joblib/parallel.py:1098\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1095\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m   1097\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[0;32m-> 1098\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mretrieve\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;66;03m# Make sure that we get a last message telling us we are done\u001B[39;00m\n\u001B[1;32m   1100\u001B[0m elapsed_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_start_time\n",
      "File \u001B[0;32m/Library/Python/3.9/site-packages/joblib/parallel.py:975\u001B[0m, in \u001B[0;36mParallel.retrieve\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    973\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    974\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msupports_timeout\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m--> 975\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output\u001B[38;5;241m.\u001B[39mextend(\u001B[43mjob\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    976\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    977\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output\u001B[38;5;241m.\u001B[39mextend(job\u001B[38;5;241m.\u001B[39mget())\n",
      "File \u001B[0;32m/Library/Python/3.9/site-packages/joblib/_parallel_backends.py:567\u001B[0m, in \u001B[0;36mLokyBackend.wrap_future_result\u001B[0;34m(future, timeout)\u001B[0m\n\u001B[1;32m    564\u001B[0m \u001B[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001B[39;00m\n\u001B[1;32m    565\u001B[0m \u001B[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001B[39;00m\n\u001B[1;32m    566\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 567\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfuture\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    568\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m CfTimeoutError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    569\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTimeoutError\u001B[39;00m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py:445\u001B[0m, in \u001B[0;36mFuture.result\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    443\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n\u001B[1;32m    444\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;241m==\u001B[39m FINISHED:\n\u001B[0;32m--> 445\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__get_result\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    446\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    447\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTimeoutError\u001B[39;00m()\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py:390\u001B[0m, in \u001B[0;36mFuture.__get_result\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    388\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception:\n\u001B[1;32m    389\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 390\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception\n\u001B[1;32m    391\u001B[0m     \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    392\u001B[0m         \u001B[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001B[39;00m\n\u001B[1;32m    393\u001B[0m         \u001B[38;5;28mself\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[0;31mBrokenProcessPool\u001B[0m: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable."
     ]
    }
   ],
   "source": [
    "from joblib import delayed\n",
    "from tqdm import tqdm\n",
    "res_rul = ProgressParallel(n_jobs=6)(delayed(experimentation)(data) for data in classification_dataset_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m\n",
      "\n",
      "    ----------------------------------------- GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1 -----------------------------------------\u001B[0m\n",
      "Dataset Information\n",
      "Rows: 1600\n",
      "Columns: 60\n",
      "Number of classes: 2\n",
      "Continous columns: 0\n",
      "Binary columns: 0\n",
      "Categorical columns: 20\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ Warning: This copy of Interpretable AI software is for academic purposes only and not for commercial use.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification CART mean performance:  0.5375\n",
      "\n",
      "\n",
      "OCT finished\n",
      "Classification OCT performance:  0.64375\n",
      "\n",
      "\n",
      "start OCT-H\n"
     ]
    }
   ],
   "source": [
    "res_rul = experimentation(classification_dataset_names[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = {}\n",
    "for d in res_rul:\n",
    "    result.update(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k = pd.DataFrame(result,index=[0])\n",
    "k = k.stack(level=2).sort_index()\n",
    "k = k.stack(level=2).sort_index()\n",
    "k = k.swaplevel(axis=1)\n",
    "k = k.droplevel(0)\n",
    "t=k.mean(level=0,axis=1)\n",
    "t = t.mean(axis=0)\n",
    "t.sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = k.swaplevel(axis=1)\n",
    "y = y.var(level=0,axis=1)\n",
    "y = y.mean(axis=0)\n",
    "good_tests = y[y < 0.01].index\n",
    "good = list(good_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vaild_results = k.iloc[:,k.columns.isin(good, level=1)]\n",
    "vaild_results=vaild_results.mean(level=0,axis=1)\n",
    "vaild_results.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('filename.pickle', 'rb') as handle:\n",
    "    b = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classification_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classification_dataset = classification_dataset_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "iters=1\n",
    "res_rul = {}\n",
    "sc = StandardScaler()\n",
    "names = ['Reg-CART','CART','ORT','OCT','ORT-H','OCT-H','ORT+ORT-H','OCT+OCT-H']\n",
    "df = fetch_data(classification_dataset)\n",
    "\n",
    "df, num_col, bin_col, cat_col = corr_data_for(df)\n",
    "\n",
    "y = df['target']\n",
    "X = df.loc[:, df.columns != 'target']\n",
    "#performance_by_iter = pd.DataFrame(columns = [\"Logistic Regression\", \"CART_rules\", \"OCT_rules\", \"OCTH_rules\", \"CART_rules_and_features\", \"OCT_rules_and_features\", \"OCTH_rules_and_features\"], index = np.arange(0, iters))\n",
    "print(color.BOLD + '\\n\\n    ----------------------------------------- {} -----------------------------------------'.format(classification_dataset) + color.END)\n",
    "rows_data, columns_data = X.shape\n",
    "print('Dataset Information')\n",
    "print('Rows:',rows_data,)\n",
    "print('Columns:',columns_data)\n",
    "print('Number of classes:',y.nunique())\n",
    "print('Continous columns:', len(num_col))\n",
    "print('Binary columns:', len(bin_col))\n",
    "print('Categorical columns:',len(cat_col))\n",
    "print('-------------------------------------------------')\n",
    "for it in range(iters):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = it, stratify=y)\n",
    "    X_col = X_train.columns\n",
    "    col_len = len(X_col)\n",
    "    X_test.name = \"X_test\"\n",
    "    X_train.name = \"X_train\"\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    X_train = pd.DataFrame(X_train,columns=X_col)\n",
    "    X_test = pd.DataFrame(X_test,columns=X_col)\n",
    "    factors = [round(col_len*0.5),col_len,round(col_len*1.2),round(col_len*1.4),round(col_len*1.6),round(col_len*1.8),round(col_len*2),round(col_len*2.5),round(col_len*3)]\n",
    "    factors_name = [0.5,1,1.2,1.4,1.6,1.8,2,2.5,3]\n",
    "\n",
    "\n",
    "\n",
    "    models, performance = generate_tree(X_train, y_train, X_test, y_test, n_num=1, feat_size=len(X.columns),  max_iter_hy=2,depth_grid=range(1,5), depth_grid_hy=range(1,3), complexity_bi = 0.001, complexity_hy=0.001,  Reg_CART=False, ORT=False, ORT_H=False, Clas_CART=True, OCT=True, OCT_H=False)\n",
    "    for perf,name in zip(performance,names):\n",
    "        if not not perf:\n",
    "            res_rul[(classification_dataset,name,it,1)] = sum(perf) / len(perf)\n",
    "\n",
    "    act_name = []\n",
    "    act_rules = []\n",
    "    for model,name in zip(models,names):\n",
    "        if not not model:\n",
    "            act_name += [name]\n",
    "            act_rules += [model]\n",
    "\n",
    "    datasets = gen_train_and_test_features(act_rules ,act_name , X_train, X_test)\n",
    "    for model in datasets.keys():\n",
    "        print(model)\n",
    "        X_train_rules_and_features, X_test_rules_and_features = datasets[model][0]\n",
    "        X_train_only_rules, X_test_only_rules = datasets[model][1]\n",
    "        print(len(X_train_rules_and_features.columns))\n",
    "        for len_c,fac_name in zip(factors,factors_name):\n",
    "            if len_c > len(X_train_only_rules.columns):\n",
    "                min_len = len(X_train_only_rules.columns)\n",
    "                min_name = 1\n",
    "            else:\n",
    "                min_len = len_c\n",
    "                min_name = fac_name\n",
    "            if (len_c <= X_train.shape[0]) & (len_c <= len(X_train_rules_and_features.columns)):\n",
    "                cols = SelectKBest(k=len_c).fit(X_train_rules_and_features,y_train).get_feature_names_out()\n",
    "                X_train_rules_features = X_train_rules_and_features[cols]\n",
    "                X_test_rules_features = X_test_rules_and_features[cols]\n",
    "\n",
    "                cols_1 = SelectKBest(k=min_len).fit(X_train_only_rules,y_train).get_feature_names_out()\n",
    "                X_train_rules = X_train_only_rules[cols_1]\n",
    "                X_test_rules = X_test_only_rules[cols_1]\n",
    "\n",
    "                only_rules_acc = log_regression_pipeline(X_train_rules, X_test_rules, y_train, y_test)\n",
    "                rules_and_features_acc = log_regression_pipeline(X_train_rules_features, X_test_rules_features, y_train, y_test)\n",
    "                res_rul[(classification_dataset,model + \"_LG_rules\",it,min_name)] = only_rules_acc\n",
    "                res_rul[(classification_dataset,model + \"_LG_rules_and_features\",it,fac_name)] = rules_and_features_acc\n",
    "\n",
    "                only_rules_acc_SVM = SVM_pipeline(X_train_rules, X_test_rules, y_train, y_test)\n",
    "                rules_and_features_acc_SVM = SVM_pipeline(X_train_rules_features, X_test_rules_features, y_train, y_test)\n",
    "                res_rul[(classification_dataset,model + \"_SVM_rules\",it,min_name)] = only_rules_acc_SVM\n",
    "                res_rul[(classification_dataset,model + \"_SVM_rules_and_features\",it,fac_name)] = rules_and_features_acc_SVM\n",
    "\n",
    "                only_rules_acc_NB = NB_pipeline(X_train_rules, X_test_rules, y_train, y_test)\n",
    "                rules_and_features_acc_NB = NB_pipeline(X_train_rules_features, X_test_rules_features, y_train, y_test)\n",
    "                res_rul[(classification_dataset,model + \"_NB_rules\",it,min_name)] = only_rules_acc_NB\n",
    "                res_rul[(classification_dataset,model + \"_NB_rules_and_features\",it,fac_name)] = rules_and_features_acc_NB\n",
    "\n",
    "                only_rules_acc_KNN = KNN_pipeline(X_train_rules, X_test_rules, y_train, y_test)\n",
    "                rules_and_features_acc_KNN = KNN_pipeline(X_train_rules_features, X_test_rules_features, y_train, y_test)\n",
    "                res_rul[(classification_dataset,model + \"_KNN_rules\",it,min_name)] = only_rules_acc_KNN\n",
    "                res_rul[(classification_dataset,model + \"_KNN_rules_and_features\",it,fac_name)] = rules_and_features_acc_KNN\n",
    "            else:\n",
    "                 continue\n",
    "\n",
    "    res_rul[(classification_dataset,'Logistic_Regression',it,1)] = log_regression_pipeline(X_train, X_test, y_train, y_test)\n",
    "\n",
    "    res_rul[(classification_dataset,\"Support Vector Machine\",it,1)] = SVM_pipeline(X_train, X_test, y_train, y_test)\n",
    "\n",
    "    res_rul[(classification_dataset,\"Naive Bayes\",it,1)] = NB_pipeline(X_train, X_test, y_train, y_test)\n",
    "\n",
    "    res_rul[(classification_dataset,\"K-Nearest-Neighbor\",it,1)] = KNN_pipeline(X_train, X_test, y_train, y_test)\n",
    "    with open('filename.pickle', 'wb') as handle:\n",
    "        pickle.dump(res_rul, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = SelectKBest(k=13).fit(X_train_rules_and_features,y_train).get_feature_names_out()\n",
    "X_train_rules_features = X_train_rules_and_features[cols]\n",
    "X_test_rules_features = X_test_rules_and_features[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k = pd.DataFrame(res_rul, index=[0])\n",
    "k = k.stack(level=2).sort_index()\n",
    "k = k.stack(level=2).sort_index()\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_only_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = {}\n",
    "for d in res_rul:\n",
    "    result.update(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res_rul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "round(col_len*1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = {}\n",
    "for d in res_rul:\n",
    "    result.update(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k = pd.DataFrame(res_rul, index=[0])\n",
    "k = k.stack(level=2).sort_index()\n",
    "k = k.stack(level=2).sort_index()\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[round(col_len*0.5),col_len,round(col_len*1.25),round(col_len*1.5),round(col_len*2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datasets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Sequential\n",
    "import keras.utils\n",
    "import keras_tuner\n",
    "#from tensorflow import keras\n",
    "from keras import utils as np_utils\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def NN_creator(hp):\n",
    "  model = Sequential()\n",
    "  model.add(Dense(30, activation='relu', input_dim=30))\n",
    "\n",
    "  # Tune the number of dense layers\n",
    "  for i in range(hp.Int('num_layers', 1, 5)):\n",
    "\n",
    "    # Tune the number of units in the each dense layer\n",
    "    hp_units = hp.Int('units_'+str(i), min_value=3, max_value=18,step=1)\n",
    "    model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
    "\n",
    "    # Tune the dropout rate in the each dense layer\n",
    "    hp_dropout = hp.Float('rate', min_value=0.0, max_value=0.5, step=0.1)\n",
    "    model.add(keras.layers.Dropout(hp_dropout))\n",
    "\n",
    "  # Add dense output layer\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "  # Tune the learning rate for the optimizer\n",
    "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a935b482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(nrows = 5, ncols = 4, gridspec_kw = {\"hspace\": 0.25})\n",
    "import seaborn as sns\n",
    "fig.set_size_inches(30, 25)\n",
    "iteration = 0\n",
    "\n",
    "for m in range(5):\n",
    "    for j in range(4):\n",
    "\n",
    "        dataset = classification_dataset_names[:20][iteration]\n",
    "\n",
    "        columns = [i for i in k.columns if dataset in i]\n",
    "        sns.boxplot(k[columns], ax = ax[m, j])\n",
    "\n",
    "        ax[m, j].set_title(dataset)\n",
    "\n",
    "        ax[m, j].set_xticklabels(['CART Rules', \"OCT Rules\", \"Logistic Regression\", \"RuleFit\", \"ORRFA\"])\n",
    "\n",
    "        iteration += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2bb77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CART_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e4f4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.violinplot(data=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27cefcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d06e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del performance_by_iter['OCTH_rules']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a166560",
   "metadata": {},
   "outputs": [],
   "source": [
    "del performance_by_iter['OCTH_rules_and_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e2c960",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[eval(rule)].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc560a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = X_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb79589",
   "metadata": {},
   "outputs": [],
   "source": [
    "rule = rule.replace(\"feature\", \"df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff36319",
   "metadata": {},
   "outputs": [],
   "source": [
    "rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ab8c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc[eval(rule)].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a5efa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rule = rules[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8af6003",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, rules in enumerate(act_rules):\n",
    "    print(i)\n",
    "    print(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e6a767",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746991b1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f58967",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, rules in enumerate(act_rules):\n",
    "    print(i)\n",
    "    print(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30830c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_by_iter.rename(columns = {column: column.replace(\"OCT_rules_and_features\", \"ORRFA\")}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94a02e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "fig, ax = plt.subplots()\n",
    "sns.boxplot(data = performance_by_iter)\n",
    "fig.set_size_inches(20, 10)\n",
    "ax.set_xticklabels(performance_by_iter.columns.values)\n",
    "# ax.set_ylim(0.93, 0.995)\n",
    "ax.tick_params(rotation = 0, labelsize = 14)\n",
    "ax.set_ylabel(\"Accuracy\", fontsize = 14)\n",
    "ax.set_title(\"Accuracy of Logistic Regression, RuleFit and ORRFA\", fontsize = 15)\n",
    "# ax.set_ylabel()\n",
    "plt.savefig('Benchmark ORRFA.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91219303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5682f5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_by_iter.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
